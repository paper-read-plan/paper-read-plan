# VLDB 2022

## Volume15，No.1

ANN Softmax: Acceleration of Extreme Classification Training

关键字：softmax，深度学习，分类任务

摘要内容：随着GPU的普及和计算能力的增长，越来越多的深度学习任务，如人脸识别、图像检索、单词嵌入等，都可以利用极端分类来提高精度。基于抽样的方法能够降低数百万类带来的巨大内存和计算消耗，但它们大多存在以下两个问题:

i)重要的类被忽略或只部分采样，导致准确率下降。

ii)由于不兼容GPU，实现效率低。

针对上述问题，本文提出了一种新的基于采样的softmax算法——ANN softmax。具体地说，我们采用二进制量化和反向文件系统来提高重要类的召回率。通过专门的内核设计，可以在主流培训框架中实现完全并行化。同时我们引入样本分组优化来很好地逼近全类训练。我们提出的方法保持了与Full Softmax相同的精度，只有1/10的采样类。

---------------------------------------------

WindTunnel: Towards Differentiable ML Pipelines Beyond a Single Model

关键字：机器学习，流水线--

摘要内容：本文提出了WindTunnel，一个将训练好的ML流水线转换为神经网络模块流水线的系统，避免了ML陷入局部优化的缺点，并使用反向传播联合优化模块。我们还提出了几种针对不可微分算子的翻译方法论，如梯度增强树和分类特征编码器。

-------------------------------

DBOS: A DBMS-oriented Operating System

关键字：操作系统，分布式，集群调度

摘要内容：本文构建一个可伸缩集群操作系统堆栈替换单个节点操作系统上，同时使用独立的集群调度器、分布式文件系统和网络管理器。这样一个数据库操作系统(DBOS)可以进行调度、文件管理和进程间通信，其性能与现有系统相比具有竞争力。此外，通过将操作系统服务实现为标准数据库查询，可以提供明显更好的分析，并大幅降低代码复杂性。

--------------------------------

Deep Indexed Active Learning for Matching Heterogeneous Entity Representations

关键字：实体解析（ER），主动学习

摘要内容：给定两个大型记录列表，实体解析(ER)中的任务是从列表的笛卡尔乘积中找到对应于相同现实世界实体的对。通常情况下，像EM这样的被动学习方法需要大量的标记数据来生成有用的模型相比之下主动学习是低资源环境下很有潜力的实体解析（ER）方法。我们提出了一种可扩展的主动学习方法DIAL，结合学习嵌入以提高召回率和匹配块对的准确性。

---------------------------------------

A Learned Query Rewrite System using Monte Carlo Tree Search

关键字：查询重写，并行树搜索，蒙特卡洛书搜索

摘要内容：查询重写将一个SQL查询转换为一个等价的查询，但具有更高的性能。然而，SQL重写是np-hard的问题，现有的方法采用启发式方法重写查询。这些启发式有两个主要的限制。

* 首先，应用不同重写规则的顺序显著影响查询性能。然而，重写顺序的研究空间随着查询操作符和规则数量呈指数增长，很难找到最优的重写顺序。现有的方法应用预定义的顺序来重写查询，并将陷入局部最优。

* 其次，不同的重写规则对不同的查询有不同程度的收益程度，现有的方法不能有效地估计效益。


为了解决这些挑战，我们提出了一个基于策略树的查询重写框架，其中根节点是输入的查询，每个节点是来自其父节点的查询重构。我们的目标是探索树中的节点，以找到最佳的重写查询。我们提出使用蒙特卡洛树搜索来探索策略树，它可以有效地导航策略树以获得最优节点。此外，我们提出了一个基于学习的模型来估计每个重写查询的预期性能改进，从而更准确地指导树搜索。为了提高算法性能，我们还提出了一种并行树搜索算法。实验结果表明，我们的方法明显优于现有的方法。

--------------------------------------------

On Detecting Cherry-picked Generalizations

关键字：查询优化，聚合

摘要内容：从详细数据的泛化转化到广义语境的陈述通常对用户理解大型数据集至关重要。我们提出了一个通过改进聚合查询来检测和解释精选泛化的框架，同时提出了一种评分方法来表示泛化的适当性。我们设计了有效的分数计算算法。为了更好地理解结果得分，我们还制定了实用的解释任务，以揭示重要的异常案例，并为陈述提供更好的替代方案。

---------------------------------------------------------

FACE: A Normalizing Flow based Cardinality Estimator

关键字：查询优化，机器学习，基数估计，蒙特卡洛

摘要内容：基数估计是查询优化中的一个重要问题。最近，基于机器学习的技术被提出来有效地估计基数，这可以大致分为查询驱动和数据驱动的方法。

* 查询驱动方法从查询学习回归模型到它的基数
* 而数据驱动的方法学习元组的分布，选择一些满足SQL查询的样本，并使用这些所选元组的数据分布来估计SQL查询的基数。

由于查询驱动方法依赖于训练查询，当没有高质量的训练查询时，估计质量不可靠；而数据驱动方法则没有这种限制，具有较高的自适应能力。在这项工作中，我们专注于**数据驱动**的方法。一个好的数据驱动模型应该实现三个优化目标。

* 首先，模型需要捕获列之间的数据依赖关系，并支持大域大小(实现高精度)。
* 其次，模型应该达到较高的推理效率，因为需要大量的数据样本来估计基数(达到较低的推理延迟)。
* 第三，模型不能太大(实现小模型尺寸)。

然而，现有的数据驱动方法无法同时优化这三个目标。为了解决这些局限性，我们提出了一种新的基数估计器FACE，它利用基于归一化流的模型来学习关系数据的连续联合分布。FACE可以将连续随机变量上的复杂分布转化为简单分布(如多元正态分布)，并利用概率密度估计基数。

-----------------------------------------------

Learned Cardinality Estimation: A Design Space Exploration and A Comparative Evaluation

关键字：查询优化，基数估计，深度学习

摘要内容：基数估计用于预测SQL查询的结果数，它是数据库管理系统查询优化器的核心。非学习方法，特别是基于直方图和抽样的方法，几十年来一直是主要的方法，在商业和开源dbms中被广泛使用。然而，直方图和抽样只能用来总结一个或几个列，这无法捕获任意列组合上的联合数据分布，因为直方图和抽样在原始关系表上过于简化。因此，对于困难的情况，例如对多个列的查询、使用多个谓词和多个表之间的连接，这些传统方法通常预测不好。近年来，习得的基数估计量得到了广泛的研究。由于最近(深度学习)模型的发展，这些学习估计器可以更好地捕捉数据分布和查询特征，因此在许多情况下，它们的性能优于非学习方法。本文的目的是为学会的基数估计器提供一个设计空间的探索，并对最先进的学会的方法进行全面的比较，从而为从业者在各种实际场景下决定使用什么方法提供指导。

-----------------------------------------------

DeepEverest: Accelerating Declarative Top-K Queries for Deep Neural Network Interpretation

关键字：深度学习，查询优化，索引

摘要内容：我们设计、实现并评估了DeepEverest，这是一个通过对深度神经网络激活值的示例查询来高效执行解释的系统。DeepEverest由一个高效的索引技术和一个具有各种优化的查询执行算法组成。对我们的原型实现的实验表明，DeepEverest只使用了不到20%的全物化存储，显著地加快了单个查询的速度，最高可达63倍，并且在模拟DNN解释过程的多查询工作负载上始终优于其他方法。

------------------------------------------------

Cosine: A Cloud-Cost Optimized Self-Designing Key-Value Storage Engine

关键字：KV存储引擎，云开销

摘要内容：我们设计了一种键值存储引擎cos，在给定输入工作负载、云预算、目标性能的情况下，它总是可以采用接近“完美”的引擎架构。通过确定和形式化存储引擎布局和核心键-值算法的第一原则，cos为三个云提供商(AWS、GCP和Azure)构建了一个庞大的设计空间，涵盖了不同的硬件空间和云定价策略。cos结合了多种设计，如对数结构合并树、对数结构哈希表、用于过滤器和索引的内存加速器，以及数万亿的混合设计，这些设计在文献或行业中没有出现，但作为上述有效的组合出现。

----------------------------------------------

Accelerating Recommendation System Training by Leveraging Popular Choices

关键字：GPU加速，神经网络，推荐系统

摘要内容：推荐模型通常用于为电子商务和基于在线广告的应用程序向用户推荐相关项目。这些模型使用大量嵌入表来存储项目和用户分类变量的数字表示(内存密集型)，并使用神经网络(计算密集型)生成最终推荐。训练这些大规模的推荐模型需要越来越多的数据和计算资源。这些模型中高度并行的神经网络部分可以从GPU加速中受益，但是大型嵌入表往往无法适应容量有限的GPU设备内存。因此，本文深入研究了训练数据的语义，并对这些模型的特征访问、传输和使用模式进行了深入的研究。我们观察到，由于某些输入的广泛使用，对嵌入的访问是高度倾斜的，一些嵌入条目被访问的次数高达10000倍以上。本文利用这种非对称访问模式提供了一个称为FAE的框架，并提出了一种用于训练推荐模型的热嵌入感知数据布局。这种布局利用了稀缺的GPU内存来存储高访问的嵌入，从而减少了数据从CPU到GPU的传输。与此同时，FAE利用GPU加速这些热门条目的执行。

## Volume 15，No 2

(p,q)-biclique Counting and Enumeration for Large Sparse Bipartite Graphs

关键字：图神经网络，DFS

摘要内容：本文研究了大型稀疏二部图的计数和枚举问题。计数和枚举问题在图神经网络信息聚合、最密集子图检测和内聚子群分析等方面有着广泛的应用。在本文中，我们提出了一种竞争分支定界基线方法，即BCList，它以深度优先的方式探索搜索空间，并结合多种修剪技术。我们提出了一种高级的方法，称为BCList++。它应用了一种基于层的探索策略，我们通过一个案例研究表明优化了图神经网络的效率。

----------

Evaluating Query Languages and Systems for High-Energy Physics Data

关键字：查询优化，性能分析

摘要内容：在高能物理(HEP)领域，数据完全结构化的查询语言SQL接受度有限。为了深入了解这种现象，我们使用HEP基准对六个不同的通用数据处理平台进行了全面分析，观察发现它们的查询语言在如何表达自然和简洁的HEP查询模式方面差别很大，要使它们与高效能分析的研究人员相关，仍有大量的工作要做。

-----------------

Distributed Hop-Constrained s-t Simple Path Enumeration at Billion Scale

关键字：分布式系统，图分析，负载均衡

摘要内容：跳跃约束s-t简单路径(HC-s-t path)枚举是图分析中的一个基本问题，近年来受到了广泛关注。直接的分布式解决方案在十亿级图中处理这个问题时，由于无法修剪无结果的探索或巨大的内存消耗，效率低下，可伸缩性差。基于此，本文旨在设计一种高效且可扩展的分布式算法来枚举十亿级图中的HC-s-t路径。我们首先提出了一种新的混合搜索范式，为HC-s-t路径枚举量身定制。基于新的搜索范式，设计了一种分而治之的分布式枚举算法。该算法不仅可以减少无结果的搜索，而且在充分利用计算资源的情况下，可以很好地约束内存消耗。我们还设计了一个有效的工作负载平衡机制，由空闲机器自动触发，以处理倾斜的工作负载。此外，我们还探索了双向搜索策略，以进一步提高枚举效率。实验结果证明了该算法的有效性。

------------

ETO: Accelerating Optimization of DNN Operators by High-Performance Tensor Program Reuse

关键字：神经网络，编译，启发式算法

摘要内容：近年来，深度神经网络(DNNs)在各种应用中取得了巨大的成功，降低DNN的响应延迟成为将其应用于多种应用的关键问题。现有的解决方案要么手动调优内核库，要么利用基于esearch的编译来减少操作符延迟。然而，手动调优需要大量的工程工作，而且巨大的搜索空间使得基于搜索编译的搜索成本在某些情况下难以承受。在这项工作中，我们提出了一个基于重用性能张量程序信息的加速DNN算子优化的框架Heracles。具体来说，Heracles为两个操作符之间的信息重用定义了条件。对于满足条件的算子，在给定一个算子的性能张量程序的情况下，Heracles使用基于重用的调优器显著地削减了另一个算子的搜索空间，同时保持了良好的有效性。heracles还提出了一种方法，通过在两个不满足重用条件的算子之间注入额外的算子作为桥梁来增加一组算子之间的重用机会，并证明了增加最小额外算子集的问题是NP-hard问题。Heracles使用启发式方法添加额外的运算符，将重用关系决策问题作为有向斯坦纳树问题来解决。实验结果表明，Heracles算法在优化dnn算子方面是有效的。

------------

Babelfish: Efficient Execution of Polyglot Queries

关键字：执行引擎，数据处理，硬件

摘要内容：数据处理系统的用户来自不同的领域，具有不同的专业水平，并偏爱不同的编程语言。结果，分析工作负载需求从关系查询转移到涉及用户定义函数(udf)的多语言查询。尽管一些数据处理系统支持多语言查询，但它们通常嵌入第三方语言运行时。这种嵌入会带来很高的性能开销，因为它会在执行引擎之间造成额外的数据物化。在本文中，我们提出了Babelfish，一个为多语言查询设计的新型数据处理引擎。Babelfish引入了一种中间表示，它统一了来自不同实现语言的查询。这使得可以跨操作符和语言边界进行新的整体优化，例如，操作符融合和工作负载专门化。因此，Babelfish避免了数据传输，并能够有效利用硬件资源。我们的评估表明，Babelfish的性能比最先进的数据处理系统高出一个数量级，达到了手写代码的性能。通过Babelfish，我们弥合了关系udf和多语言udf之间的性能差距，并为未来多语言工作负载的高效执行奠定了基础。

---------------

Butterfly Counting on Uncertain Bipartite Networks 

关键字：启发式，不确定蝴蝶计数

摘要内容：当考虑不确定的二部网络时，常用的graphlet结构butterfly的实例数可以作为快速度量网络信息的一个重要指标。这种不确定蝴蝶计数在各种领域都有实际用途，如生物医学/生物领域，电子商务和道路网络。在本文中，我们正式定义了不确定蝴蝶结构(其中蝴蝶的存在概率大于或等于某个用户定义的阈值t)和不确定蝴蝶数量问题(确定任何不确定二部网络上该结构的唯一实例的数量)。然后，我们通过提出一个非平凡的基线解决方案(𝑈𝐵𝐹𝐶)和一个改进的解决方案(𝐼𝑈𝐵𝐹𝐶)来检验精确的解决方案，该解决方案减少了时间复杂度，并在实践中使用启发式进一步减少了运行时。除了精确解，我们通过抽样提出了两个近似解𝑈𝐵𝑆和𝑃𝐸𝑆，可以用来快速估计不确定蝴蝶数量，当不需要精确计数时，这是一个强大的工具。利用一系列具有不同边缘存在概率分布的网络，我们验证了我们的解决方案的效率和有效性。

------------

METRO: A Generic Graph Neural Network Framework for Multivariate Time Series Forecasting

关键字：时序，华为云

摘要内容：多变量时间序列预测由于其广泛的应用而受到越来越多的关注。人们普遍认为，利用变量对之间的潜在依赖关系可以提高预测精度。然而，现有的方法大多采用静态变量相关性建模，忽略了时间尺度之间的相关性，未能充分保留变量之间的动态和周期性的相互依赖关系，而这对长期和短期预测至关重要。本文提出了一种基于多尺度时间图神经网络的通用框架METRO，该框架可以同时对动态变量和跨尺度变量的相关性进行建模。通过将多变量时间序列表示为一系列时间图，可以通过消息传递和节点嵌入更新很好地保持步内和步间的相关性。为了实现跨时间尺度的信息传播，我们设计了一种新的采样策略，使高、低尺度之间的特定步骤对齐，并有效地融合跨尺度的信息。此外，我们提供了现有的基于gnn的时间序列预测工作的模块化解释，作为我们框架下的具体实例。在四个基准数据集上进行的大量实验证明了我们的方法的有效性和效率。METRO已经成功部署到华为云的时间序列分析平台上，一个月的在线测试表明，与最先进的模型w.r.t. RSE相比，METRO可以实现高达20%的相对改进。

---------------------

LargeEA: Aligning Entities for Large-scale Knowledge Graphs

关键字：知识图谱

摘要内容：实体对齐(EA)的目的是在不同的知识图(KGs)中找到等价的实体。近年来，EA得到了快速的发展，目前的EA方法主要依靠其结构特征来对齐等价实体。当前的EA方法存在可伸缩性问题，限制了它们在真实EA场景中的使用。为了解决这一问题，我们提出LargeEA来对齐大型知识图谱之间的实体。LargeEA由两个通道组成，即结构通道和名称通道。对于结构通道，我们提出了METIS-CPS(一种节省内存的小批生成策略)，将大知识图谱划分为更小的小批，并在每个小批中独立学习实体的结构特征。LargeEA是一个通用的工具，可以很容易地与现有的任何EA方法集成，从大型知识图谱中学习实体的结构特征。对于名称通道，我们首先引入了NFF(一种名称特征融合方法)，以捕获实体的丰富名称特征，而不涉及任何复杂的训练过程。然后，我们利用基于名称的数据增强来生成种子对齐，无需任何人工干预。这样的设计更适合常见的现实场景，因为种子对齐并不总是可用的。最后，LargeEA通过融合实体的结构特征和名称特征得到EA结果。由于目前还没有一个被广泛认可的EA基准用于大规模的EA评估，我们还从真实的kg中提取了一个名为DBP1M的大规模EA基准。大量的实验证实了LargeEA相对于最先进的竞争对手的优势。

-------------

HVS: Hierarchical Graph Structure Based on Voronoi Diagrams for Solving Approximate Nearest Neighbor Search

关键字：信息检索，查询优化，图搜索

摘要内容：近似最近邻搜索(ANNS)是信息检索和数据挖掘中的一个基本问题，有着广泛的应用。在最先进的内存ANNS方法中，基于图的方法因其卓越的效率和查询准确性而引起了特别的兴趣。这些方法大多关注于边的选择以缩短搜索路径，而不太关注每一跳的计算量。为了降低成本，我们提出了一种新的图结构HVS。HVS具有多层的层次结构，对应着一系列由粗到细的子空间划分。此外，我们在每个层中使用虚拟Voronoi图来加速搜索。通过遍历Voronoi单元，HVS可以有效地到达给定查询的最近邻居，从而降低了总搜索成本。实验证明，HVS优于其他最先进的基于图的方法。

-------------

Origami: A High-Performance Mergesort Framework

关键字：归并排序，并行优化

摘要内容：归并排序是现实工作负载的流行内核，因为它不受数据偏斜的影响，支持流操作，并行化相对不那么复杂。我们介绍了Origami，这是一个归并排序框架，它提供了一个四阶段的管道，并为每个阶段开发了可推广到标量和所有SIMD CPU体系结构的优化解决方案。在相同的扩展集中，我们提出了对小序列排序的最快的寄存器内方法和排序列表的无分支合并，它比单纯合并实现了高达1.5倍的加速。此外，我们引入了缓存驻留的四叉合并树以避免内存带宽的瓶颈，并引入了并行分区方案以最大化线程级别的并行性。我们使用这些组件开发端到端排序，并通过减少阶段之间的同步开销来产生一个高度利用的管道。Origami单线程归并排序的执行速度比最接近的竞争对手快2倍，在多核环境中实现了近乎完美的加速

-------------

Learning to be a Statistician: Learned Estimator for Number of Distinct Values

关键字：NDV估计，监督学习，机器学习

摘要内容：估计一个列中不同值(NDV)的数量对于数据库系统中的许多任务都很有用，比如列存储压缩和数据分析。在这项工作中，我们专注于如何从随机(在线/离线)样本中获得准确的NDV估计。这种有效的估计对于禁止扫描数据甚至一次的任务是至关重要的。现有的基于样本的估计器通常依赖于启发式或假设，在不同的数据集上没有健壮的性能，因为数据上的假设很容易被打破。另一方面，从一个原则性的公式(如极大似然估计)推导出一个估计量是非常具有挑战性的，因为这个公式的结构非常复杂。我们提出在监督学习框架下构建NDV估计任务，目的是学习一个模型作为估计量。为此，我们需要回答以下几个问题:i)如何使学习到的模型工作量不可知;Ii)如何获取培训数据;Iii)如何进行模型训练。我们推导出学习框架的条件，在这种条件下，学习到的模型与工作负载无关，即模型/估计器可以用综合生成的训练数据进行训练，然后简单地部署到任何数据仓库中，例如，用户定义函数(udf)，为不可见的表和工作负载提供高效(在微秒内)和准确的NDV估计。我们将学习到的估计量与九个真实世界数据集上最先进的基于样本的估计量进行比较，以证明其优越的估计精度。为了再现性，我们在网上发布了我们学到的估计器。

-------------

ParChain: A Framework for Parallel Hierarchical Agglomerative Clustering using Nearest-Neighbor Chain

关键字：查询优化，最近邻链算法，HAC，聚类

摘要内容：本文研究了层次聚类问题，其目标是生成一个树状图来表示在数据集的不同规模的聚类。我们提出了设计并行层次凝聚聚类(HAC)算法的ParChain框架，并利用该框架获得了针对完全链接、平均链接和Ward’s链接准则的新型并行算法。与以往大多数并行HAC算法需要二次元内存相比，我们的新算法只需要线性内存，并且可扩展到大型数据集。ParChain基于我们对最近邻链算法的并行化，允许在每一轮中合并多个集群。我们介绍了两个对效率至关重要的关键优化:一个是范围查询优化，它在寻找集群的最近邻居时减少了所需的距离计算数量;另一个是缓存优化，它存储了以前计算的距离的子集，这些距离很可能被重用。实验表明，我们的高度优化实现使用48核和超线程，在最先进的并行HAC算法上实现5.8 - 110.1倍的加速，并实现13.75 - 54.23倍的自相对加速。与最先进的算法相比，我们的算法所需的空间减少了237.3倍。我们的算法能够扩展到具有数千万个点的数据集大小，这是现有算法无法处理的。

-------------

Answering Regular Path Queries through Exemplars

关键字：RPQ，图分析，正则表达式

摘要内容：常规简单路径查询(RPQ)是图分析中的基本操作之一。在RPQ中，输入是一个图、一个源节点和一个正则表达式。目标是识别通过一个简单路径连接到源的所有节点，其标签序列满足给定的正则表达式。正则表达式充当用户感兴趣的搜索空间的正式规范。尽管正则表达式具有很高的表达能力，但对于非技术用户来说，它是一个障碍。此外，要充分实现正则表达式的强大功能，用户必须熟悉图数据集的领域。在本研究中，我们通过将rpq与按例查询范式连接起来来解决这个瓶颈。更具体地说，我们要求用户提供描述感兴趣路径的样例对，然后从这个样例自动推断出正则表达式。这个新问题带来了几个新的挑战。我们如何推断正则表达式?考虑到回答rpq是np困难的，我们如何扩展到更大的图表?我们通过Biermann和Feldman的算法与nfa引导的随机漫步与重启的独特结合来解决这些挑战。在多个真实的百万级数据集上的大量实验表明，RQuBE比基线策略至少快3个数量级，平均准确率超过90%。

------------

HET: Scaling out Huge Embedding Model Training via Cache-enabled Distributed Framework

关键字： 嵌入模型，通信

摘要内容：嵌入模型被认为是高维数据的一种有效的学习范式。然而，嵌入模型的一个尚未解决的问题是其表示(潜在因素)往往导致较大的参数空间。我们观察到现有的分布式训练框架面临嵌入模型的可伸缩性问题，因为从服务器更新和检索共享的嵌入参数通常主导着训练周期。在本文中，我们提出了一种新的系统框架HET，它显著提高了大型嵌入模型训练的可扩展性。我们将倾斜的嵌入流行度分布作为一个性能机会，并利用它来解决使用嵌入缓存的通信瓶颈。为了确保缓存之间的一致性，我们在HET设计中加入了一个新的一致性模型，它在每个嵌入的基础上提供了细粒度的一致性保证。与以前的工作相比，HET只允许读操作的过时性，它还利用了写操作的过时性。对六个代表性任务的评估表明，与最先进的基线相比，HET实现了高达88%的嵌入通信减少和高达20.68倍的性能加速。

------------

FINEdex: A Fine-grained Learned Index Scheme for Scalable and Concurrent Memory Systems

关键字：深度学习，索引优化

摘要内容：内存系统中的索引结构对于提高整个系统的性能非常重要。有前途的学习索引利用深度学习模型来补充现有的索引结构，并获得显著的性能改进。现有的方案依赖增量缓冲区来支持可伸缩性，但当插入大量数据时，由于需要检查学习到的索引和额外的增量缓冲区，会产生很高的开销。由于数据依赖性高，共享的增量缓冲区很快变大，需要频繁的再训练，因此实际系统性能也会下降。为了解决可扩展性有限和频繁再训练的问题，我们提出了一种高可扩展性的细粒度学习索引方案，称为FINEdex，它在经过训练的数据数组下用扁平的数据结构(即数据相关性低的数据数组)构造独立的模型，以低开销并发处理请求。通过进一步有效地探索和利用工作负载的特征，FINEdex在非阻塞再培训的支持下及时处理新请求，从而适应新的分布而不阻塞系统。我们通过YCSB和真实数据集对FINEdex进行了评估，大量的实验结果表明，FINEdex的性能分别比最先进的XIndex和Masstree提高了1.8倍和2.5倍。我们已经在GitHub上发布了FINEdex的开源代码供公众使用。

------------

TaGSim: Type-aware Graph Similarity Learning and Computation

关键字：深度学习，GED（图编辑距离）

摘要内容：在基于图的应用程序中，计算图之间的相似性是一个基本和关键的问题，最常用的图相似性度量之一是图编辑距离(GED)，它被定义为将一个图转换为另一个图的图编辑操作的最小数量。现有的GED解决方案存在严重的性能问题，特别是由于精确的GED计算的np硬度。近年来，深度学习在计算精度高、计算成本低的GED逼近方面显示出良好的前景。然而，现有的方法将GED视为一个全局的、粗粒度的图相似度值，而忽略了不同类型的图编辑操作(包括节点插入/删除、节点重标记、边缘插入/删除和边缘重标记)所产生的特定类型的变革影响。在本文中，我们提出了一种类型感知图相似度学习和计算框架TaGSim(类型感知图相似度)，该框架在不同的图编辑类型下以细粒度方法估计GED。具体来说，对于每一种类型的图编辑操作，TaGSim都对其对图的独特变化影响进行建模，并将其编码为高质量的、类型感知的图嵌入，这些嵌入被进一步馈送到类型感知的神经网络中，以实现精确的GED估计。在5个真实数据集上的大量实验证明了TaGSim的有效性和效率，它明显优于最先进的GED解决方案。

------------

Analysis of Influence Contribution in Social Advertising

关键字：ICA（影响贡献分配）

摘要内容：在当今的社交广告模式中，在线社交网络(OSN)提供商通常通过在推广帖子中插入社交广告来进行广告活动。每当用户参与推广广告时，参与广告的用户可能会进一步递归地将推广广告传播给她的追随者，这个传播过程被称为口碑效应。为了广泛而有效地传播推广级联，OSN提供商通常倾向于选择在社交网络上拥有大量受众的影响者来发起广告活动。这种营销模式，也被称为影响者营销，已经获得了越来越多的关注和投资，并迅速成为数字营销中最广泛使用的渠道之一。在本文中，考虑广告的病毒式传播，即影响贡献分配(ICA)，在给定活动结果的情况下，我们制定了OSN提供商获取影响者影响力贡献的问题。我们将协同决策与合作博弈论中的Shapley值概念联系起来，揭示协同决策背后的理论基础。获取ICA的解决方案的一种简单方法是枚举交付活动结果的所有可能级联，导致潜在级联的指数数量相对于用户之间的连接数量，这在计算上是难以处理的。此外，生成产生精确战役结果的级联也并非易事。面对这些挑战，我们在线性阈值(LT)模型下建立了一个线性时间精确解，并在独立级联(IC)模型下设计了一个完全多项式时间随机逼近方案(FPRAS)。具体而言，在IC模型下，我们提出了一种有效的方法，通过设计一种具有可证明精度保证的可扩展采样方法来估计概率图中osn建模的预期影响贡献。我们进行了大量的实验，并表明我们的算法在几个基线上产生了显著更高质量的解决方案，并显著提高了采样效率。

------------

Scabbard: Single-Node Fault-Tolerant Stream Processing

关键字：单节点，SPE（流处理引擎）

摘要内容：单节点多核流处理引擎(spe)每秒可以处理数亿元组。然而，在保持这种性能的同时，用精确一次的语义实现它们的容错是一个开放的挑战:由于单个节点的I/O带宽有限，在执行过程中持久保存所有流数据和操作符状态是不可实现的。相反，单节点spe依赖上游分布式系统，如Apache Kafka，在故障后恢复流数据，这需要复杂的基于集群的部署。缺乏内置的容错特性阻碍了单节点spe的采用。我们描述了鞘巴德，第一个单节点SPE，它支持精确一次的容错语义，尽管本地I/O带宽有限。剑鞘通过将持久性操作与查询工作负载集成来实现这一点。在操作符图中，鞘根据操作符的选择性来决定何时持久化流:通过在丢弃数据的操作符之后持久化流，它可以大幅减少所需的I/O带宽。作为操作符图的一部分，鞘巴德支持并行持久性操作，并使用标记来决定何时丢弃持久性数据。使用特定于工作负载的压缩可进一步减少持久数据量:鞘巴德监视流统计信息，并动态生成计算效率高的压缩操作符。我们的实验表明，剑鞘可以执行每秒处理超过2亿元组的流查询，同时以亚秒级的延迟从失败中恢复。

------------

Enabling Personal Consent in Databases

关键字：关系数据库，用户管理

摘要内容：用户有权同意使用他们的数据，但目前的方法仅限于非常粗粒度的同意表达，如对某些用途的“选择加入/选择退出”选择。在本文中，我们确定了细粒度同意管理的需要，并形式化了如何表达和管理关系数据库中数据使用的用户同意和个人契约。与隐私保护方法不同，我们的重点不是对对手保持机密性，而是与受信任的服务提供商合作，以算法的方式遵守用户偏好。我们的方法使数据所有者能够在正式规范中表达预期的数据使用，我们称之为同意约束，并使希望遵守这些约束的服务提供者能够通过过滤违反同意的查询结果来自动做到这一点;而不是双方都依赖自然语言写的“使用条款”协议。我们提供了形式化的基础(基于来源)、算法(基于统一和查询重写)、到数据隐私的连接以及支持数据库中的同意的复杂性结果。我们在一个开源RDBMS中实现了我们的框架，并使用TPC-H基准对最相关的隐私方法进行了评估，并在一个真正的ICU数据集上进行了评估。

------------