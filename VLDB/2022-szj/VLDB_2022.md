# VLDB 2022

## Volume15，No.1

ANN Softmax: Acceleration of Extreme Classification Training

关键字：softmax，深度学习，分类任务

摘要内容：随着GPU的普及和计算能力的增长，越来越多的深度学习任务，如人脸识别、图像检索、单词嵌入等，都可以利用极端分类来提高精度。基于抽样的方法能够降低数百万类带来的巨大内存和计算消耗，但它们大多存在以下两个问题:

i)重要的类被忽略或只部分采样，导致准确率下降。

ii)由于不兼容GPU，实现效率低。

针对上述问题，本文提出了一种新的基于采样的softmax算法——ANN softmax。具体地说，我们采用二进制量化和反向文件系统来提高重要类的召回率。通过专门的内核设计，可以在主流培训框架中实现完全并行化。同时我们引入样本分组优化来很好地逼近全类训练。我们提出的方法保持了与Full Softmax相同的精度，只有1/10的采样类。

---------------------------------------------

WindTunnel: Towards Differentiable ML Pipelines Beyond a Single Model

关键字：机器学习，流水线--

摘要内容：本文提出了WindTunnel，一个将训练好的ML流水线转换为神经网络模块流水线的系统，避免了ML陷入局部优化的缺点，并使用反向传播联合优化模块。我们还提出了几种针对不可微分算子的翻译方法论，如梯度增强树和分类特征编码器。

 -------------------------------

DBOS: A DBMS-oriented Operating System

关键字：操作系统，分布式，集群调度

摘要内容：本文构建一个可伸缩集群操作系统堆栈替换单个节点操作系统上，同时使用独立的集群调度器、分布式文件系统和网络管理器。这样一个数据库操作系统(DBOS)可以进行调度、文件管理和进程间通信，其性能与现有系统相比具有竞争力。此外，通过将操作系统服务实现为标准数据库查询，可以提供明显更好的分析，并大幅降低代码复杂性。

 --------------------------------

Deep Indexed Active Learning for Matching Heterogeneous Entity Representations

关键字：实体解析（ER），主动学习

摘要内容：给定两个大型记录列表，实体解析(ER)中的任务是从列表的笛卡尔乘积中找到对应于相同现实世界实体的对。通常情况下，像EM这样的被动学习方法需要大量的标记数据来生成有用的模型相比之下主动学习是低资源环境下很有潜力的实体解析（ER）方法。我们提出了一种可扩展的主动学习方法DIAL，结合学习嵌入以提高召回率和匹配块对的准确性。

 ---------------------------------------

A Learned Query Rewrite System using Monte Carlo Tree Search

关键字：查询重写，并行树搜索，蒙特卡洛书搜索

摘要内容：查询重写将一个SQL查询转换为一个等价的查询，但具有更高的性能。然而，SQL重写是np-hard的问题，现有的方法采用启发式方法重写查询。这些启发式有两个主要的限制。

* 首先，应用不同重写规则的顺序显著影响查询性能。然而，重写顺序的研究空间随着查询操作符和规则数量呈指数增长，很难找到最优的重写顺序。现有的方法应用预定义的顺序来重写查询，并将陷入局部最优。

* 其次，不同的重写规则对不同的查询有不同程度的收益程度，现有的方法不能有效地估计效益。


为了解决这些挑战，我们提出了一个基于策略树的查询重写框架，其中根节点是输入的查询，每个节点是来自其父节点的查询重构。我们的目标是探索树中的节点，以找到最佳的重写查询。我们提出使用蒙特卡洛树搜索来探索策略树，它可以有效地导航策略树以获得最优节点。此外，我们提出了一个基于学习的模型来估计每个重写查询的预期性能改进，从而更准确地指导树搜索。为了提高算法性能，我们还提出了一种并行树搜索算法。实验结果表明，我们的方法明显优于现有的方法。

 --------------------------------------------

On Detecting Cherry-picked Generalizations

关键字：查询优化，聚合

摘要内容：从详细数据的泛化转化到广义语境的陈述通常对用户理解大型数据集至关重要。我们提出了一个通过改进聚合查询来检测和解释精选泛化的框架，同时提出了一种评分方法来表示泛化的适当性。我们设计了有效的分数计算算法。为了更好地理解结果得分，我们还制定了实用的解释任务，以揭示重要的异常案例，并为陈述提供更好的替代方案。

 ---------------------------------------------------------

FACE: A Normalizing Flow based Cardinality Estimator

关键字：查询优化，机器学习，基数估计，蒙特卡洛

摘要内容：基数估计是查询优化中的一个重要问题。最近，基于机器学习的技术被提出来有效地估计基数，这可以大致分为查询驱动和数据驱动的方法。

* 查询驱动方法从查询学习回归模型到它的基数
* 而数据驱动的方法学习元组的分布，选择一些满足SQL查询的样本，并使用这些所选元组的数据分布来估计SQL查询的基数。

由于查询驱动方法依赖于训练查询，当没有高质量的训练查询时，估计质量不可靠；而数据驱动方法则没有这种限制，具有较高的自适应能力。在这项工作中，我们专注于**数据驱动**的方法。一个好的数据驱动模型应该实现三个优化目标。

* 首先，模型需要捕获列之间的数据依赖关系，并支持大域大小(实现高精度)。
* 其次，模型应该达到较高的推理效率，因为需要大量的数据样本来估计基数(达到较低的推理延迟)。
* 第三，模型不能太大(实现小模型尺寸)。

然而，现有的数据驱动方法无法同时优化这三个目标。为了解决这些局限性，我们提出了一种新的基数估计器FACE，它利用基于归一化流的模型来学习关系数据的连续联合分布。FACE可以将连续随机变量上的复杂分布转化为简单分布(如多元正态分布)，并利用概率密度估计基数。

 -----------------------------------------------

Learned Cardinality Estimation: A Design Space Exploration and A Comparative Evaluation

关键字：查询优化，基数估计，深度学习

摘要内容：基数估计用于预测SQL查询的结果数，它是数据库管理系统查询优化器的核心。非学习方法，特别是基于直方图和抽样的方法，几十年来一直是主要的方法，在商业和开源dbms中被广泛使用。然而，直方图和抽样只能用来总结一个或几个列，这无法捕获任意列组合上的联合数据分布，因为直方图和抽样在原始关系表上过于简化。因此，对于困难的情况，例如对多个列的查询、使用多个谓词和多个表之间的连接，这些传统方法通常预测不好。近年来，习得的基数估计量得到了广泛的研究。由于最近(深度学习)模型的发展，这些学习估计器可以更好地捕捉数据分布和查询特征，因此在许多情况下，它们的性能优于非学习方法。本文的目的是为学会的基数估计器提供一个设计空间的探索，并对最先进的学会的方法进行全面的比较，从而为从业者在各种实际场景下决定使用什么方法提供指导。

 -----------------------------------------------

DeepEverest: Accelerating Declarative Top-K Queries for Deep Neural Network Interpretation

关键字：深度学习，查询优化，索引

摘要内容：我们设计、实现并评估了DeepEverest，这是一个通过对深度神经网络激活值的示例查询来高效执行解释的系统。DeepEverest由一个高效的索引技术和一个具有各种优化的查询执行算法组成。对我们的原型实现的实验表明，DeepEverest只使用了不到20%的全物化存储，显著地加快了单个查询的速度，最高可达63倍，并且在模拟DNN解释过程的多查询工作负载上始终优于其他方法。

 ------------------------------------------------

Cosine: A Cloud-Cost Optimized Self-Designing Key-Value Storage Engine

关键字：KV存储引擎，云开销

摘要内容：我们设计了一种键值存储引擎cos，在给定输入工作负载、云预算、目标性能的情况下，它总是可以采用接近“完美”的引擎架构。通过确定和形式化存储引擎布局和核心键-值算法的第一原则，cos为三个云提供商(AWS、GCP和Azure)构建了一个庞大的设计空间，涵盖了不同的硬件空间和云定价策略。cos结合了多种设计，如对数结构合并树、对数结构哈希表、用于过滤器和索引的内存加速器，以及数万亿的混合设计，这些设计在文献或行业中没有出现，但作为上述有效的组合出现。

 ----------------------------------------------

Accelerating Recommendation System Training by Leveraging Popular Choices

关键字：GPU加速，神经网络，推荐系统

摘要内容：推荐模型通常用于为电子商务和基于在线广告的应用程序向用户推荐相关项目。这些模型使用大量嵌入表来存储项目和用户分类变量的数字表示(内存密集型)，并使用神经网络(计算密集型)生成最终推荐。训练这些大规模的推荐模型需要越来越多的数据和计算资源。这些模型中高度并行的神经网络部分可以从GPU加速中受益，但是大型嵌入表往往无法适应容量有限的GPU设备内存。因此，本文深入研究了训练数据的语义，并对这些模型的特征访问、传输和使用模式进行了深入的研究。我们观察到，由于某些输入的广泛使用，对嵌入的访问是高度倾斜的，一些嵌入条目被访问的次数高达10000倍以上。本文利用这种非对称访问模式提供了一个称为FAE的框架，并提出了一种用于训练推荐模型的热嵌入感知数据布局。这种布局利用了稀缺的GPU内存来存储高访问的嵌入，从而减少了数据从CPU到GPU的传输。与此同时，FAE利用GPU加速这些热门条目的执行。