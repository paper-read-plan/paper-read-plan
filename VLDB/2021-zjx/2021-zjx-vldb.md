# 2021-vldb

Benchmarking Learned Indexes

+ 关键词：ml，index

+ 摘要：通过自主学习获得的索引模型代替传统的b-tree模型，在这项工作中，我们提出了一个统一的基准，它将三种已经学习过的索引结构的调优实现与几种最先进的“传统”基准进行比较。通过使用四个真实的数据集，我们证明了在内存中只读工作负载下，学习得到的索引结构在密集数组上的性能确实优于非学习索引。我们研究了缓存、流水线、数据集大小和键值大小的影响。我们研究了学习得到的索引结构的性能，并建立了一个解释为什么学习得到的模型能取得如此好的性能。最后，我们研究了学习得到索引结构的其他重要特性，例如它们在多线程系统中的性能和构建时间。



Tempura: A General Cost-Based Optimizer Framework for Incremental Data Processing

+ 关键词：增量数据处理
+ 摘要：增量处理被广泛应用于许多应用中，从增量视图维护、流计算，到最近出现的渐进式数据仓库和间歇性查询处理。尽管针对这个主题开发了许多算法，但没有一种算法能够产生始终达到最佳性能的增量计划，因为最优计划是依赖于数据的。在本文中，我们开发了一种新的基于成本的优化框架，称为Tempura，用于优化增量数据处理。 我们提出了一种基于时变关系概念的增量查询规划模型TIP，它可以以最一般的形式对增量处理进行形式化建模。我们给出Tempura的细节，使用者可以根据需求添加自己的处理规则，我们研究如何探索计划空间，并寻找一个最优的增量计划。我们在各种增量处理场景中评估Tempura，以展示其有效性和效率



NeuroCard: One Cardinality Estimator for All Tables

+ 关键词：查询优化，基数
+ 摘要：查询优化器依赖准确的基数估计来生成良好的执行计划。 尽管经过几十年的研究，现有的基数估计对于复杂的查询来说是不准确的，因为它会做出有损的建模假设，并且不能捕获表间的相关性， 在这项工作中，我们表明，在没有任何独立假设的情况下，学习数据库中所有表的相关性是可能的，我们设计了NeuroCard，一个连接基数估计器，它在整个数据库上构建单个神经密度估计器。利用连接抽样和现代深度自回归模型，neucard在其概率建模中不做表间或列间独立的假设。NeuroCard实现了比之前最好的方法更高的数量级的精度(一个新的最先进的结果，8.5×最大误差的JOB-light)，可扩展到几十个表，同时紧凑的空间(几个mb)和高效的构建或更新(秒到分钟)。



Permutable Compiled Queries: Dynamically Adapting Compiled Queries without Recompiling

+ 关键词：查询优化，JIT

+ 摘要：即时编译计数（JIT）是一种提升DBMS查询计划编译效率的方法。但是编译每个查询的成本相对于它的执行时间来说是相关度极高的。如果数据的分布同预估的不同，这样的开销阻止DBMS使用一些自适应查询生成方式去生成新的查询计划。优化器可以为一个查询生成许多的子查询计划，但每个子查询计划都只能考虑一部分因素，因为考虑多因素将会显著增加编译的成本。

  我们提出了一种称为Permutable Compiled Queries(PCQ)的方法，它弥合了JIT编译和AQP之间的差距。允许 DBMS可以修改已编译的查询，而不需要重新编译或在查询开始前包含所有可能的变量。利用PCQ，DBMS间接构造查询代码，使DBMS即使在运行时也能更改查询计划。我们在内存DBMS中实现PCQ，并在微基准测试中与非自适应计划和最先进的分析DBMS进行比较。我们的评估表明，PCQ比静态计划的性能好4倍以上，在分析基准上比其他DBMS的性能好2倍以上。



Taurus: Lightweight Parallel Logging for In-Memory Database Management Systems

+ 关键词：日志，并行，并发系统

+ 摘要：现有的单流日志记录方案不适合内存数据库管理系统，因为单个日志常常成为性能瓶颈。为了克服这个问题，我们提出Taurus是一种高效的并行日志记录方案，它使用多个日志流，与数据和命令日志记录兼容。

  Taurus使用一个日志序列号(lsn)向量来跟踪和编码事务依赖关系。这些向量确保在日志记录中完全捕获依赖项，并在恢复中正确执行。我们使用内存DBMS进行的实验评估表明，Taurus的并行日志记录比单流数据日志记录和命令日志记录分别达到 9.9× 和 2.9× 的加速。它还使DBMS恢复高达22.9×和比这些基线的数据和命令日志记录速度分别快75.6倍。我们还将Taurus与两种最先进的并行日志记录方案进行了比较，结果表明DBMS达到了2.8× NVMe驱动器和9.2× hdd上的性能。



Improving Execution Eficiency of Just-in-time Compilation based Qery Processing on GPUs

+ 关键词：JIT，查询优化，GPU
+ 摘要：近年来，我们见证了在图形处理单元(gpu)上改进联机分析处理(OLAP)性能的重大努力。由于内存限制对gpu的查询处理性能起着至关重要的作用，现有的研究大多集中在提高内存效率上。由于最近查询处理中JIT (just-in-time, JIT)编译的兴起，我们研究了是否以及如何进一步提高GPU上的查询处理性能。具体来说，我们研究最先进的基于编译的JIT查询处理系统的执行。我们发现，多亏了数据库压缩和JIT编译等高级技术，内存限制不再是最重要的瓶颈。相反，由于资源争用导致的执行分歧和并行度下降，当前基于编译的JIT查询处理会遇到严重的GPU硬件利用率不足。为了解决这些问题，我们提出了一个名为Pyper的基于JIT编译的查询引擎，以提高查询执行期间的GPU利用率。具体来说，Pyper有两个新操作算子，Shufe和Segment，用于查询计划转换，可以插入到物理查询计划中，以分别减少执行分歧和解决资源争用。为了确定这两个操作算子的插入点，我们提出了一个分析模型，可以帮助以基于成本的方式将Shufe和Segment操作符插入到查询计划中。实验结果表明:
  + 发散执行和资源争用的解析分析有助于提高成本模型的准确性;
  + Pyper在TPC-H和SSB查询上的性能明显优于其他GPU查询引擎。



Aggregated Deletion Propagation for Counting Conjunctive Qery Answers∗

+ 关键词：查询
+ 摘要：为了从连接查询的输出中移除给定数量的元组，我们研究了最小化源副作用的计算复杂性。这是一个经过充分研究的删除传播问题的变体，不同的是，我们感兴趣的是删除输入元组的最小子集来删除给定数量的输出元组，而删除传播专注于删除特定的输出元组。我们称之为聚合删除传播问题。我们完全刻画了无自连接的任意连接查询的多时间可解性。这包括一个确定可解性的多时间算法，以及NP-hard实例的精确结构表征。我们还提供了一个实用的算法(NP-hard实例的启发式算法)，并评估了其在真实和合成数据集上的实验性能



Breaking Down Memory Walls: Adaptive Memory Management in LSM-based Storage Systems

+ 关键词：内存管理，LSM tree
+ 摘要：LSM-trees在现代NoSQL系统中得到了广泛的应用。 由于非原地更新的设计，lsm树在多个lsm 树的内存组件之间以及写内存和缓冲区缓存之间引入了内存屏障。这些区域之间的最佳内存分配并不简单，因为它高度依赖于工作负载。现有的LSM-tree实现采用静态内存分配方案，因为它们简单和健壮，牺牲了性能。在本文中，我们试图在基于lsm的存储系统中打破这些内存屏障。我们首先介绍了一个支持自适应内存管理的内存管理架构。然后，我们提出了一种分区内存组件结构，采用新的fush策略，以更好地利用写内存，最大限度地减少写开销。为了打破写内存和缓冲区缓存之间的内存墙，我们进一步引入了一个内存调优器，它对这两个区域之间的内存分配进行调优。我们在Apache环境中的AsterixDB使用YCSB和TPC-C基准测试进行了大量的实验 ，我们将在这里展示结果。



Elle: Inferring Isolation Anomalies from Experimental Observations

+ 关键词：事务，分布式数据库
+ 摘要：因为分布式数据库通常不能保证他们所保证的事务隔离级别，而作为用户需要对这些分布式数据库进行观察，从而确定其能保证的隔离级别。



CoroBase: Coroutine-Oriented Main-Memory Database Engine

+ 关键词：协程，事务

+ 摘要：由于使用了富指针的数据结构，数据屏障是主内存数据库引擎中的主要开销。轻量级协程简化了软件预取的实现，通过重叠计算和异步数据预取来隐藏数据停滞。以前的解决方案主要集中于(1)单个组件和操作，以及(2)需要更改接口的事务内部批处理，从而破坏了向后兼容性。目前还不清楚它们如何应用于完整的数据库引擎，以及它们在各种工作负载下能带来多少端到端好处。

  本文介绍了CoroBase，这是一个主内存数据库引擎，它通过一种新的协程到事务的范式来解决这些挑战。协程到事务模型将事务作为协程，从而支持事务间批处理，避免了应用程序更改，但保留了预取的好处。我们展示了在一个48核的服务器上，CoroBase对于读密集型工作负载的性能提高了近2倍，并且对于那些不能从软件预取中受益的工作负载仍然具有竞争力。



Scalable Querying of Nested Data

+ 关键词：查询优化

+ 摘要：虽然大型分布式数据处理平台已经成为查询处理的一个有吸引力的目标，但这些系统对于处理嵌套集合的应用程序来说是有问题的。程序员被迫要么执行收集程序的重要转换，要么使用自动化的扁平化过程，这两者都会导致性能问题。对于具有倾斜基数的嵌套集合，这些挑战只会变得更糟，手工重写和自动扁平化都无法实现跨分区的负载平衡。

  在这项工作中，我们提出了一个框架，该框架将操作嵌套集合的程序转换为一组语义上等价的可有效计算的分解查询。该框架结合使用了查询编译技术、嵌套集合的高效数据表示和自动倾斜处理。我们提供了一个广泛的实验评估，展示了该框架在嵌套收集程序的不同场景中提供的显著改进。



Astrid: Accurate Selectivity Estimation for String Predicates using Deep Learning

+ 关键词：查询优化，深度学习

+ 摘要：准确估计字符串谓词的选择性是数据库中一个长期存在的研究挑战。支持字符串上的模式匹配(如前缀、子字符串和后缀)使这个问题更具挑战性，因此需要专门进行研究。

  传统方法通常构建修剪过的汇总数据结构，比如尝试之后使用统计相关性进行选择性估计。但是，这会产生不够准确的基数估计，导致查询优化器选择次优计划。最近提出的基于深度学习的方法利用了来自自然语言处理(如嵌入)的技术来编码字符串，并使用它来训练模型。虽然这是对传统方法的改进，但仍有很大的改进空间。

  我们提出了Astrid，一个用于字符串选择性估计的框架，综合了传统和基于深度学习的方法的想法。我们做出了两个互补的贡献。首先，我们提出了一个查询类型(前缀、子字符串和后缀)和选择性感知的嵌入算法。考虑三个字符串' ab '、' abc '和' abd '，前缀频率分别为1000、800和100。我们的方法将确保嵌入' ab '比' abd '更接近' abc '。其次，我们描述了神经语言模型如何用于选择性估计。虽然它们可以很好地用于前缀查询，但它们对于子字符串查询的性能却不是最优的。我们修改了神经语言模型的目标函数，使其可以用于估计模式匹配查询的选择性。我们还提出了一个新的和有效的算法来优化新的目标函数。我们在基准数据集上进行了广泛的实验，并表明我们提出的方法取得了最先进的结果。



Mainlining Databases: Supporting Fast Transactional Workloads on Universal Columnar Data File Formats

+ 关键词：文件格式

+ 摘要：现代数据处理工具的普及已经产生了开放源码的柱状数据格式。这些格式有助于组织避免为每个应用程序重复将数据转换为新格式。但是，这些格式是只读的，组织必须使用重量级的转换流程来从联机事务处理(OLTP)系统加载数据。因此，dbms在传输数据时常常不能充分利用网络带宽。我们的目标是通过为内存中的数据库管理系统(dbms)开发一种存储架构来减少甚至消除这种开销，这种存储架构能够意识到其数据的最终使用情况，并以通用的开源格式发出柱状存储块。我们对常见的分析数据格式进行了放宽，以有效地更新记录，并依赖轻量级的转换过程在块冷时将其转换为读取优化的布局。我们还描述了如何以最小的序列化开销从第三方分析工具访问数据。

  我们基于Apache Arrow格式实现了存储引擎，并将其集成到NoisePage DBMS中以评估我们的工作。我们的实验表明，与现有方法相比，我们的方法在实现向外部数据科学和机器学习工具输出快数量级的数据的同时，在专用OLTP dbms上实现了相当的性能。



FlashP: An Analytical Pipeline for Real-time Forecasting of Time-Series Relational Data

+ 关键词：数据采样，时间序列
+ 摘要：在分析管道中，交互响应时间对于用户探索足够数量的可能性并做出明智的业务决策非常重要。我们考虑了一个具有大量高维时间序列数据的预测管道。实时预报可分两步进行。首先，我们通过对数据进行切片、切割和聚合来指定要关注的数据部分和要预测的度量。其次，将聚合的结果训练为预测模型，对特定测度的趋势进行预测。虽然有许多可用的预测模型，但第一步是性能瓶颈。一个很自然的想法是利用采样来获得实时的近似聚合，作为训练预测模型的输入。基于这一思想，我们构建了可扩展的实时预测系统FlashP (Flash Prediction)，本文要解决的主要问题有两个:一是近似聚集对预测模型拟合和预测结果的影响;其次，相应地，我们应该使用什么抽样算法来获得这些近似的聚合以及样本有多大。本文介绍了一种新的抽样方法，即GSW抽样，并分析了利用GSW样本估计聚合的误差范围。我们介绍了如何构造致密的、存在多种待分析测度的GSW样本。我们通过实验来评估我们的解决方案及其在真实数据上的替代方案。



Epoch-based Commit and Replication in Distributed OLTP Databases

+ 关键词：分布式系统，事务处理，2PC
+ 摘要：许多现代面向数据的应用程序都构建在分布式OLTP数据库之上，以实现可伸缩性和高可用性。这种分布式数据库通过两阶段提交(2PC)和同步复制在每个事务的粒度上实现原子性、持久性和一致性。在本文中，我们提出了一种新的分布式OLTP数据库COCO，它支持基于epoch的提交和复制。COCO背后的关键思想是，它将事务分成多个时代，并将整个时代的事务作为提交单元。这样，的开销2PC和同步复制显著减少。我们支持两种乐观并发控制(OCC)，使用物理时间和逻辑时间进行各种优化，这是基于epoch的执行所启用的。我们在两个流行的基准(YCSB和TPC-C)上的评估表明，COCO的性能比具有细粒度2PC和同步复制的系统高出四倍。



Adaptive Code Generation for Data-Intensive Analytics

+ 关键词：查询优化，动态编码
+ 摘要：现代数据库管理系统采用了复杂的查询优化技术，能够为非常大的数据集上的查询生成有效的计划。许多其他应用程序也处理大型数据集，但不能为其代码利用数据库样式的查询优化。因此，我们找到了一个利用数据库样式的查询优化来增强开源编程语言编译器的机会。我们的系统在查询时动态生成执行计划，并每次在数据块上运行这些计划。根据早期块的反馈，可以为以后的块使用替代计划。编译器扩展可用于各种数据密集型应用程序，使它们都能从这类性能优化中受益。



Building Enclave-Native Storage Engines for Practical Encrypted Databases

+ 关键词：加密
+ 摘要：数据保密性是阻碍企业客户将工作负载转移到云端的最大问题之一。由于可信执行环境(TEE)，现在可以在飞地中构建加密数据库，处理客户数据，同时对云保密。尽管最近出现了一些基于飞地的加密数据库，但关于如何以不同的方式实现机密性，以及这些数据库隐含的影响，还有很大一块未探索的领域。在本文中，我们首先对构建加密数据库存储引擎、在安全性、性能和功能方面进行权衡的可能设计选择进行了广泛的探索。我们观察到，不同维度上的选择可以是独立的，它们的组合决定了整个存储的整体交易。然后我们提出Enclage，这是一种进行实际权衡的加密存储引擎。它采用了许多enclave-native设计，如页面级加密、减少enclave交互、分层内存缓冲区等，在提供高级安全保障的同时，也提供了高性能。为了更好地利用有限的飞地内存，我们推导出飞地中最优的页面大小，并采用增量解密，以较低的成本访问大数据页。我们的实验表明，Enclage的吞吐量比许多加密数据库中常见的存储设计基准高出13倍以上，存储节省约5倍。



Tensor Relational Algebra for Distributed Machine Learning System Design

+ 关键词：SQL，评价系统
+ 摘要：SQL的过程扩展已经存在了几十年。然而，很少有人知道它们在现实工作负载中的使用程度和复杂性。在RDBMS中执行过程代码的效率低下和局限性是众所周知的;因此，有几项努力来解决这个问题。然而，缺乏对它们在实际工作负载中使用的理解，使得(a)激发这一领域的新工作，(b)识别研究挑战和机会，以及(c)展示新作品的影响。我们的目标是通过我们的工作应对这些挑战。在本文中，我们展示了对数千个存储过程、用户定义函数和触发器进行深入分析的结果，这些数据来自于几种实际工作负载。我们引入了SQL-ProcBench，这是rdbms中过程性工作负载的基准。SQL-ProcBench是根据我们的分析创建的，因此代表了真实的工作负载。利用SQL-ProcBench，我们在几种数据库引擎上进行了实验评估，以理解和识别研究的挑战和机遇。我们强调需要在这些有趣和相关的问题上进行工作，并鼓励研究人员在这一领域做出贡献。



Database Isolation By Scheduling

+ 关键词：隔离级别，锁，事务处理

+ 摘要：事务隔离通常通过限制对数据库中物理项的访问来实现。为了最大限度地提高性能，隔离功能通常与恢复、I/O和数据访问方法打包在一个单一事务存储管理器中。

  虽然这种设计在历史上为在线事务处理系统提供了高性能，但行业趋势表明，人们越来越需要一种新方法，将事务存储管理器的交织组件分解为模块化服务。提出了一种隔离组件模块化的新方法。我们的工作基于谓词锁定，这是一种隔离机制，通过锁定数据库中的逻辑项而不是物理项来实现模块化。谓词锁定很少用作核心隔离机制，因为它具有很高的理论复杂性和感知开销。但是，我们证明，通过优化常见谓词结构，可以在实践中大大减少这种开销。

  我们提出了DIBS，这是一个事务调度器，它使用我们的谓词锁定优化来保证作为模块化服务的隔离。我们评估了DIBS作为数据处理系统中唯一的隔离机制的性能。在此设置中，在TATP工作负载上，DIBS可扩展到每秒1050万个事务。我们还将探讨如何将DIBS应用于现有数据库系统以提高事务吞吐量。在SQLite中，DIBS将在TATP上每个事务的文件系统写操作减少了90%，从而使吞吐量提高了3倍。最后，DIBS减少了MySQL中YCSB上的行争用，提供了可序列化的隔离，吞吐量提高了1.4倍。



FLAT: Fast, Lightweight and Accurate Method for Cardinality Estimation

+ 关键词：查询优化，基数估计
+ 摘要：查询优化器依赖于精确的基数估计(CardEst)来产生良好的执行计划。CardEst的核心问题是如何精确而紧凑地对属性的丰富联合分布进行建模。尽管经过了几十年的研究，现有的方法要么只使用独立因子分解对模型进行过度简化，导致估计不准确，要么不使用独立假设的无损条件因子分解使模型过于复杂，导致概率计算缓慢。本文提出了一种同时具有概率计算速度快、模型规模轻、估计质量准确的CardEst方法FLAT。FLAT的关键思想是一种新的无监督图形模型，称为FSPN。它同时利用独立因子分解和条件因子分解对不同层次的属性相关性进行自适应建模，并结合它们的优点。FLAT支持在近线性时间内对底层FSPN模型进行高效的在线概率计算，提供有效的精细模型构建并支持增量模型更新。它可以估计单表查询和多表连接查询的基数。大量的实验研究证明了FLAT方法优于现有的CardEst方法:FLAT实现提高1-5个数量级的精度，提高1-3个数量级的概率计算速度，降低1-2个数量级的存储成本。我们还将FLAT集成到Postgres中以执行端到端测试。在众所周知的IMDB基准工作负载上，它将查询执行时间提高了12.9%，非常接近使用真实基数的最佳结果14.2%。



Are We Ready For Learned Cardinality Estimation?

+ 关键词：查询优化，计数估计，ml
+ 摘要：基数估计是查询优化中一个基本但长期未解决的问题。最近，来自不同研究小组的多篇论文一致报道，学习模型有潜力取代现有的基数估计。在本文中，我们提出了一个前瞻性的问题:我们准备好在生产中部署这些学习得到的基数模型了吗？我们的研究主要包含三个部分。首先，我们关注静态环境(即没有数据更新)，并在统一工作负载设置下，在四个真实数据集上比较五种新学习的方法与九种传统方法。结果表明，学习模型确实比传统方法更准确，但往往存在较高的训练和推理成本。其次，我们探究这些学习过的模型是否为动态环境做好了准备(例如，频繁的数据更新)。我们发现它们无法赶上快速的数据更新，并由于不同的原因返回较大的错误。对于不太频繁的更新，它们可以表现得更好，但它们之间没有明显的赢家。第三，我们对学习过的模型进行更深入的研究，并探索它们何时可能出错。我们的结果表明，学习方法的性能可以受到相关性、偏度或域大小的变化的很大影响。更重要的是，他们的行为更难以解释，而且往往难以预测。基于这些发现，我们确定了两个有前途的研究方向(控制学习模型的成本和使学习模型可信)，并提出了一些研究机会。我们希望我们的研究可以指导研究人员和实践者一起工作，最终将学习到的基数估计器推向真实的数据库系统。



PATSQL: Efficient Synthesis of SQL Queries from Example Tables with Quick Inference of Projected Columns

+ 关键词：SQL
+ 摘要：SQL是最受欢迎的数据分析工具之一,它现在被越来越多的用户使用,而没有在数据库中拥有专业知识。一些研究已经提出了以编程为例的方法来帮助这些非专家编写正确的SQL查询。虽然现有的方法支持各种SQL特性,如聚合和嵌套查询,但随着示例表的规模增加,它们在计算成本上有显著的增加。在本文中,我们提出了一种有效的算法,利用关系代数中已知的属性来合成来自输入和输出表的SQL查询。我们的关键见解是，通过在关系代数中应用转换规则，在保留程序语义的同时，可以将程序草图中的投影操作符提升到其他操作符之上。这使得可以在投影运算符中快速推断出适当的列，这是合成中的一个基本组成部分，但在以前的工作中会导致组合爆炸。我们还介绍了一种新的约束形式及其自顶向下的传播机制，以实现高效的草图完成。我们在我们的工具PATSQL中实现了这个算法，并对来自之前基准测试和Kaggle教程的226个查询进行了评估。结果，PATSQL解决了68%的基准，并在一秒钟内找到89%的解。我们的工具可以在https://naist-se.github.io/patsql/上找到。



Fauce: Fast and Accurate Deep Ensembles with Uncertainty for Cardinality Estimation

+ 关键词：ml，基数估计

+ 摘要：基数估计是数据库中一个基本而关键的问题。近年来，人们提出了许多基于深度学习的估计方法来解决这一问题，并取得了良好的效果。但是，这些估计器很难为复杂的查询提供准确的结果，因为它们不能捕获真正的列间和表间相关性。此外，这些估计量都不包含关于其估计的不确定性信息。在本文中，我们提出了一个称为Fauce的连接基数估计器。Fauce学习数据库中所有列和所有表之间的相关性。它还包含了每个估计的不确定性信息。在所有研究过的估计器中，我们的结果是有希望的：1）Fauce是一种轻量级的估计器，它的推理速度比现有的估计器快10倍；2）Fauce对复杂查询具有鲁棒性，与现有的估计器相比，它为复杂查询提供了1.3×-6.7×更小的估计误差；3）据我们所知，Fauce是第一个将不确定性信息整合到深度学习模型中进行基数估计的估计器

  

Flow-Loss: Learning Cardinality Estimates That Mater

+ 关键词：基数估计，查询优化
+ 摘要：近年来，人们对利用机器学习来提高基数估计的准确性非常感兴趣。这项工作的重点是提高平均估计误差，但并不是所有的估计对下游任务(如查询优化)都同等重要。由于学习过的模型不可避免地会出错，所以目标应该是改进对优化器产生最大影响的估计。我们引入了一个新的损失函数，Flow-Loss，用于学习基数估计模型。流损失近似于优化器的成本模型和搜索算法，它使用解析函数显式优化更好的查询计划。Flow-Loss的核心是将查询优化简化为一个特定平面图上的前路径问题，其中不同的路径对应不同的查询计划。为了评估我们的方法，我们引入基数估计基准(CEB)，它包含超过16K 查询的子计划的基本真理基数，这些查询来自21个模板，最多有15个连接。我们表明，在不同的体系结构和数据库中，使用Flow-Loss训练的模型改善了计划成本和查询运行时，尽管其估计精度比使用QError训练的模型差。当测试集查询与训练查询密切匹配时，使用两个损失函数训练的模型表现良好。然而，当对稍微不同的查询(例如，相似但不可见的查询模板)进行评估时，q - error训练模型显著降级，而flow - loss训练模型更适用于这种情况，在具有相同模型架构和训练数据的不可见模板上实现了4 - 8倍更好的99分位数运行时间。



Robustness against Read Committed for Transaction Templates

+ 关键词：事务，隔离级别
+ 摘要：众所周知，许多数据库系统提供的隔离级多版本读提交(RC)是为了提高事务吞吐量而牺牲一致性的。有时，事务工作负载可以在RC下安全执行，以较低的RC成本获得序列化性的完美隔离。为了识别这种情况，我们引入了事务程序的表达模型，以更好地解释事务工作负载的可序列化性。我们开发了可处理的算法来决定在RC下执行的工作负载的任何可能的时间表是否可序列化(称为鲁棒性问题)。我们的方法产生的健壮子集比以前的方法所识别的子集要大。我们提供的实验证据表明，与较强的隔离级别相比，抗RC的工作负载在RC下可以更快地进行评估。我们将讨论通过提升对更新的选择性读操作，使RC工作负载健壮的技术。根据场景的不同，性能的提高可能相当可观。因此，在较低的隔离级别RC下进行健壮性测试和安全执行事务可以提供一种直接的方法，在不改变DBMS内部的情况下提高事务吞吐量。



Scaling Replicated State Machines with Compartmentalization

+ 关键词：状态机，raft，分区
+ 摘要：状态机复制协议，如MultiPaxos和Raft，是许多分布式系统和数据库的关键组件。然而，由于一些瓶颈组件，这些协议提供了相对较低的吞吐量。许多现有的协议孤立地修复不同的瓶颈，但缺乏完整的解决方案。当你解决了一个瓶颈，另一个瓶颈就会出现。在本文中，我们介绍了分区技术，这是第一种消除状态机复制瓶颈的综合技术。划分涉及到将单个瓶颈分离到不同的组件中，并独立地扩展这些组件。划分有两个关键优势。首先，划分会带来强大的性能。在本文中，我们演示了如何划分MultiPaxos，以便在只写工作负载下将吞吐量提高6×，在混合读写工作负载下提高16×。与其他方法不同，我们不需要专门的硬件就可以实现这种性能。第二，划分是一种技术，而不是协议。行业从业者可以增量地将分区应用到他们的协议中，而不必采用一个全新的协议。



Constructing and Analyzing the LSM Compaction Design Space

+ 关键词：
+ 摘要： LSM tree通过附加写入（append）数据提供了高效的摄入，因此被广泛用作生产NoSQL数据存储的存储层。