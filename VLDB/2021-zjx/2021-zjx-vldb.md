# 2021-vldb

Benchmarking Learned Indexes

+ 关键词：ml，index

+ 摘要：通过自主学习获得的索引模型代替传统的b-tree模型，在这项工作中，我们提出了一个统一的基准，它将三种已经学习过的索引结构的调优实现与几种最先进的“传统”基准进行比较。通过使用四个真实的数据集，我们证明了在内存中只读工作负载下，学习得到的索引结构在密集数组上的性能确实优于非学习索引。我们研究了缓存、流水线、数据集大小和键值大小的影响。我们研究了学习得到的索引结构的性能，并建立了一个解释为什么学习得到的模型能取得如此好的性能。最后，我们研究了学习得到索引结构的其他重要特性，例如它们在多线程系统中的性能和构建时间。



Tempura: A General Cost-Based Optimizer Framework for Incremental Data Processing

+ 关键词：增量数据处理
+ 摘要：增量处理被广泛应用于许多应用中，从增量视图维护、流计算，到最近出现的渐进式数据仓库和间歇性查询处理。尽管针对这个主题开发了许多算法，但没有一种算法能够产生始终达到最佳性能的增量计划，因为最优计划是依赖于数据的。在本文中，我们开发了一种新的基于成本的优化框架，称为Tempura，用于优化增量数据处理。 我们提出了一种基于时变关系概念的增量查询规划模型TIP，它可以以最一般的形式对增量处理进行形式化建模。我们给出Tempura的细节，使用者可以根据需求添加自己的处理规则，我们研究如何探索计划空间，并寻找一个最优的增量计划。我们在各种增量处理场景中评估Tempura，以展示其有效性和效率



NeuroCard: One Cardinality Estimator for All Tables

+ 关键词：查询优化，基数
+ 摘要：查询优化器依赖准确的基数估计来生成良好的执行计划。 尽管经过几十年的研究，现有的基数估计对于复杂的查询来说是不准确的，因为它会做出有损的建模假设，并且不能捕获表间的相关性， 在这项工作中，我们表明，在没有任何独立假设的情况下，学习数据库中所有表的相关性是可能的，我们设计了NeuroCard，一个连接基数估计器，它在整个数据库上构建单个神经密度估计器。利用连接抽样和现代深度自回归模型，neucard在其概率建模中不做表间或列间独立的假设。NeuroCard实现了比之前最好的方法更高的数量级的精度(一个新的最先进的结果，8.5×最大误差的JOB-light)，可扩展到几十个表，同时紧凑的空间(几个mb)和高效的构建或更新(秒到分钟)。



Permutable Compiled Queries: Dynamically Adapting Compiled Queries without Recompiling

+ 关键词：查询优化，JIT

+ 摘要：即时编译计数（JIT）是一种提升DBMS查询计划编译效率的方法。但是编译每个查询的成本相对于它的执行时间来说是相关度极高的。如果数据的分布同预估的不同，这样的开销阻止DBMS使用一些自适应查询生成方式去生成新的查询计划。优化器可以为一个查询生成许多的子查询计划，但每个子查询计划都只能考虑一部分因素，因为考虑多因素将会显著增加编译的成本。

  我们提出了一种称为Permutable Compiled Queries(PCQ)的方法，它弥合了JIT编译和AQP之间的差距。允许 DBMS可以修改已编译的查询，而不需要重新编译或在查询开始前包含所有可能的变量。利用PCQ，DBMS间接构造查询代码，使DBMS即使在运行时也能更改查询计划。我们在内存DBMS中实现PCQ，并在微基准测试中与非自适应计划和最先进的分析DBMS进行比较。我们的评估表明，PCQ比静态计划的性能好4倍以上，在分析基准上比其他DBMS的性能好2倍以上。



Taurus: Lightweight Parallel Logging for In-Memory Database Management Systems

+ 关键词：日志，并行，并发系统

+ 摘要：现有的单流日志记录方案不适合内存数据库管理系统，因为单个日志常常成为性能瓶颈。为了克服这个问题，我们提出Taurus是一种高效的并行日志记录方案，它使用多个日志流，与数据和命令日志记录兼容。

  Taurus使用一个日志序列号(lsn)向量来跟踪和编码事务依赖关系。这些向量确保在日志记录中完全捕获依赖项，并在恢复中正确执行。我们使用内存DBMS进行的实验评估表明，Taurus的并行日志记录比单流数据日志记录和命令日志记录分别达到 9.9× 和 2.9× 的加速。它还使DBMS恢复高达22.9×和比这些基线的数据和命令日志记录速度分别快75.6倍。我们还将Taurus与两种最先进的并行日志记录方案进行了比较，结果表明DBMS达到了2.8× NVMe驱动器和9.2× hdd上的性能。



Improving Execution Eficiency of Just-in-time Compilation based Qery Processing on GPUs

+ 关键词：JIT，查询优化，GPU
+ 摘要：近年来，我们见证了在图形处理单元(gpu)上改进联机分析处理(OLAP)性能的重大努力。由于内存限制对gpu的查询处理性能起着至关重要的作用，现有的研究大多集中在提高内存效率上。由于最近查询处理中JIT (just-in-time, JIT)编译的兴起，我们研究了是否以及如何进一步提高GPU上的查询处理性能。具体来说，我们研究最先进的基于编译的JIT查询处理系统的执行。我们发现，多亏了数据库压缩和JIT编译等高级技术，内存限制不再是最重要的瓶颈。相反，由于资源争用导致的执行分歧和并行度下降，当前基于编译的JIT查询处理会遇到严重的GPU硬件利用率不足。为了解决这些问题，我们提出了一个名为Pyper的基于JIT编译的查询引擎，以提高查询执行期间的GPU利用率。具体来说，Pyper有两个新操作算子，Shufe和Segment，用于查询计划转换，可以插入到物理查询计划中，以分别减少执行分歧和解决资源争用。为了确定这两个操作算子的插入点，我们提出了一个分析模型，可以帮助以基于成本的方式将Shufe和Segment操作符插入到查询计划中。实验结果表明:
  + 发散执行和资源争用的解析分析有助于提高成本模型的准确性;
  + Pyper在TPC-H和SSB查询上的性能明显优于其他GPU查询引擎。



Aggregated Deletion Propagation for Counting Conjunctive Qery Answers∗

+ 关键词：查询
+ 摘要：为了从连接查询的输出中移除给定数量的元组，我们研究了最小化源副作用的计算复杂性。这是一个经过充分研究的删除传播问题的变体，不同的是，我们感兴趣的是删除输入元组的最小子集来删除给定数量的输出元组，而删除传播专注于删除特定的输出元组。我们称之为聚合删除传播问题。我们完全刻画了无自连接的任意连接查询的多时间可解性。这包括一个确定可解性的多时间算法，以及NP-hard实例的精确结构表征。我们还提供了一个实用的算法(NP-hard实例的启发式算法)，并评估了其在真实和合成数据集上的实验性能



Breaking Down Memory Walls: Adaptive Memory Management in LSM-based Storage Systems

+ 关键词：内存管理，LSM tree
+ 摘要：LSM-trees在现代NoSQL系统中得到了广泛的应用。 由于非原地更新的设计，lsm树在多个lsm 树的内存组件之间以及写内存和缓冲区缓存之间引入了内存屏障。这些区域之间的最佳内存分配并不简单，因为它高度依赖于工作负载。现有的LSM-tree实现采用静态内存分配方案，因为它们简单和健壮，牺牲了性能。在本文中，我们试图在基于lsm的存储系统中打破这些内存屏障。我们首先介绍了一个支持自适应内存管理的内存管理架构。然后，我们提出了一种分区内存组件结构，采用新的fush策略，以更好地利用写内存，最大限度地减少写开销。为了打破写内存和缓冲区缓存之间的内存墙，我们进一步引入了一个内存调优器，它对这两个区域之间的内存分配进行调优。我们在Apache环境中的AsterixDB使用YCSB和TPC-C基准测试进行了大量的实验 ，我们将在这里展示结果。



Elle: Inferring Isolation Anomalies from Experimental Observations

+ 关键词：事务，分布式数据库
+ 摘要：因为分布式数据库通常不能保证他们所保证的事务隔离级别，而作为用户需要对这些分布式数据库进行观察，从而确定其能保证的隔离级别。



CoroBase: Coroutine-Oriented Main-Memory Database Engine

+ 关键词：协程，事务

+ 摘要：由于使用了富指针的数据结构，数据屏障是主内存数据库引擎中的主要开销。轻量级协程简化了软件预取的实现，通过重叠计算和异步数据预取来隐藏数据停滞。以前的解决方案主要集中于(1)单个组件和操作，以及(2)需要更改接口的事务内部批处理，从而破坏了向后兼容性。目前还不清楚它们如何应用于完整的数据库引擎，以及它们在各种工作负载下能带来多少端到端好处。

  本文介绍了CoroBase，这是一个主内存数据库引擎，它通过一种新的协程到事务的范式来解决这些挑战。协程到事务模型将事务作为协程，从而支持事务间批处理，避免了应用程序更改，但保留了预取的好处。我们展示了在一个48核的服务器上，CoroBase对于读密集型工作负载的性能提高了近2倍，并且对于那些不能从软件预取中受益的工作负载仍然具有竞争力。



Scalable Querying of Nested Data

+ 关键词：查询优化

+ 摘要：虽然大型分布式数据处理平台已经成为查询处理的一个有吸引力的目标，但这些系统对于处理嵌套集合的应用程序来说是有问题的。程序员被迫要么执行收集程序的重要转换，要么使用自动化的扁平化过程，这两者都会导致性能问题。对于具有倾斜基数的嵌套集合，这些挑战只会变得更糟，手工重写和自动扁平化都无法实现跨分区的负载平衡。

  在这项工作中，我们提出了一个框架，该框架将操作嵌套集合的程序转换为一组语义上等价的可有效计算的分解查询。该框架结合使用了查询编译技术、嵌套集合的高效数据表示和自动倾斜处理。我们提供了一个广泛的实验评估，展示了该框架在嵌套收集程序的不同场景中提供的显著改进。



Astrid: Accurate Selectivity Estimation for String Predicates using Deep Learning

+ 关键词：查询优化，深度学习

+ 摘要：准确估计字符串谓词的选择性是数据库中一个长期存在的研究挑战。支持字符串上的模式匹配(如前缀、子字符串和后缀)使这个问题更具挑战性，因此需要专门进行研究。

  传统方法通常构建修剪过的汇总数据结构，比如尝试之后使用统计相关性进行选择性估计。但是，这会产生不够准确的基数估计，导致查询优化器选择次优计划。最近提出的基于深度学习的方法利用了来自自然语言处理(如嵌入)的技术来编码字符串，并使用它来训练模型。虽然这是对传统方法的改进，但仍有很大的改进空间。

  我们提出了Astrid，一个用于字符串选择性估计的框架，综合了传统和基于深度学习的方法的想法。我们做出了两个互补的贡献。首先，我们提出了一个查询类型(前缀、子字符串和后缀)和选择性感知的嵌入算法。考虑三个字符串' ab '、' abc '和' abd '，前缀频率分别为1000、800和100。我们的方法将确保嵌入' ab '比' abd '更接近' abc '。其次，我们描述了神经语言模型如何用于选择性估计。虽然它们可以很好地用于前缀查询，但它们对于子字符串查询的性能却不是最优的。我们修改了神经语言模型的目标函数，使其可以用于估计模式匹配查询的选择性。我们还提出了一个新的和有效的算法来优化新的目标函数。我们在基准数据集上进行了广泛的实验，并表明我们提出的方法取得了最先进的结果。



Mainlining Databases: Supporting Fast Transactional Workloads on Universal Columnar Data File Formats

+ 关键词：文件格式

+ 摘要：现代数据处理工具的普及已经产生了开放源码的柱状数据格式。这些格式有助于组织避免为每个应用程序重复将数据转换为新格式。但是，这些格式是只读的，组织必须使用重量级的转换流程来从联机事务处理(OLTP)系统加载数据。因此，dbms在传输数据时常常不能充分利用网络带宽。我们的目标是通过为内存中的数据库管理系统(dbms)开发一种存储架构来减少甚至消除这种开销，这种存储架构能够意识到其数据的最终使用情况，并以通用的开源格式发出柱状存储块。我们对常见的分析数据格式进行了放宽，以有效地更新记录，并依赖轻量级的转换过程在块冷时将其转换为读取优化的布局。我们还描述了如何以最小的序列化开销从第三方分析工具访问数据。

  我们基于Apache Arrow格式实现了存储引擎，并将其集成到NoisePage DBMS中以评估我们的工作。我们的实验表明，与现有方法相比，我们的方法在实现向外部数据科学和机器学习工具输出快数量级的数据的同时，在专用OLTP dbms上实现了相当的性能。



FlashP: An Analytical Pipeline for Real-time Forecasting of Time-Series Relational Data

+ 关键词：数据采样，时间序列
+ 摘要：在分析管道中，交互响应时间对于用户探索足够数量的可能性并做出明智的业务决策非常重要。我们考虑了一个具有大量高维时间序列数据的预测管道。实时预报可分两步进行。首先，我们通过对数据进行切片、切割和聚合来指定要关注的数据部分和要预测的度量。其次，将聚合的结果训练为预测模型，对特定测度的趋势进行预测。虽然有许多可用的预测模型，但第一步是性能瓶颈。一个很自然的想法是利用采样来获得实时的近似聚合，作为训练预测模型的输入。基于这一思想，我们构建了可扩展的实时预测系统FlashP (Flash Prediction)，本文要解决的主要问题有两个:一是近似聚集对预测模型拟合和预测结果的影响;其次，相应地，我们应该使用什么抽样算法来获得这些近似的聚合以及样本有多大。本文介绍了一种新的抽样方法，即GSW抽样，并分析了利用GSW样本估计聚合的误差范围。我们介绍了如何构造致密的、存在多种待分析测度的GSW样本。我们通过实验来评估我们的解决方案及其在真实数据上的替代方案。



Epoch-based Commit and Replication in Distributed OLTP Databases

+ 关键词：分布式系统，事务处理，2PC
+ 摘要：许多现代面向数据的应用程序都构建在分布式OLTP数据库之上，以实现可伸缩性和高可用性。这种分布式数据库通过两阶段提交(2PC)和同步复制在每个事务的粒度上实现原子性、持久性和一致性。在本文中，我们提出了一种新的分布式OLTP数据库COCO，它支持基于epoch的提交和复制。COCO背后的关键思想是，它将事务分成多个时代，并将整个时代的事务作为提交单元。这样，的开销2PC和同步复制显著减少。我们支持两种乐观并发控制(OCC)，使用物理时间和逻辑时间进行各种优化，这是基于epoch的执行所启用的。我们在两个流行的基准(YCSB和TPC-C)上的评估表明，COCO的性能比具有细粒度2PC和同步复制的系统高出四倍。



Adaptive Code Generation for Data-Intensive Analytics

+ 关键词：查询优化，动态编码
+ 摘要：现代数据库管理系统采用了复杂的查询优化技术，能够为非常大的数据集上的查询生成有效的计划。许多其他应用程序也处理大型数据集，但不能为其代码利用数据库样式的查询优化。因此，我们找到了一个利用数据库样式的查询优化来增强开源编程语言编译器的机会。我们的系统在查询时动态生成执行计划，并每次在数据块上运行这些计划。根据早期块的反馈，可以为以后的块使用替代计划。编译器扩展可用于各种数据密集型应用程序，使它们都能从这类性能优化中受益。



Building Enclave-Native Storage Engines for Practical Encrypted Databases

+ 关键词：加密
+ 摘要：数据保密性是阻碍企业客户将工作负载转移到云端的最大问题之一。由于可信执行环境(TEE)，现在可以在飞地中构建加密数据库，处理客户数据，同时对云保密。尽管最近出现了一些基于飞地的加密数据库，但关于如何以不同的方式实现机密性，以及这些数据库隐含的影响，还有很大一块未探索的领域。在本文中，我们首先对构建加密数据库存储引擎、在安全性、性能和功能方面进行权衡的可能设计选择进行了广泛的探索。我们观察到，不同维度上的选择可以是独立的，它们的组合决定了整个存储的整体交易。然后我们提出Enclage，这是一种进行实际权衡的加密存储引擎。它采用了许多enclave-native设计，如页面级加密、减少enclave交互、分层内存缓冲区等，在提供高级安全保障的同时，也提供了高性能。为了更好地利用有限的飞地内存，我们推导出飞地中最优的页面大小，并采用增量解密，以较低的成本访问大数据页。我们的实验表明，Enclage的吞吐量比许多加密数据库中常见的存储设计基准高出13倍以上，存储节省约5倍。



Tensor Relational Algebra for Distributed Machine Learning System Design

+ 关键词：SQL，评价系统
+ 摘要：SQL的过程扩展已经存在了几十年。然而，很少有人知道它们在现实工作负载中的使用程度和复杂性。在RDBMS中执行过程代码的效率低下和局限性是众所周知的;因此，有几项努力来解决这个问题。然而，缺乏对它们在实际工作负载中使用的理解，使得(a)激发这一领域的新工作，(b)识别研究挑战和机会，以及(c)展示新作品的影响。我们的目标是通过我们的工作应对这些挑战。在本文中，我们展示了对数千个存储过程、用户定义函数和触发器进行深入分析的结果，这些数据来自于几种实际工作负载。我们引入了SQL-ProcBench，这是rdbms中过程性工作负载的基准。SQL-ProcBench是根据我们的分析创建的，因此代表了真实的工作负载。利用SQL-ProcBench，我们在几种数据库引擎上进行了实验评估，以理解和识别研究的挑战和机遇。我们强调需要在这些有趣和相关的问题上进行工作，并鼓励研究人员在这一领域做出贡献。



Database Isolation By Scheduling

+ 关键词：隔离级别，锁，事务处理

+ 摘要：事务隔离通常通过限制对数据库中物理项的访问来实现。为了最大限度地提高性能，隔离功能通常与恢复、I/O和数据访问方法打包在一个单一事务存储管理器中。

  虽然这种设计在历史上为在线事务处理系统提供了高性能，但行业趋势表明，人们越来越需要一种新方法，将事务存储管理器的交织组件分解为模块化服务。提出了一种隔离组件模块化的新方法。我们的工作基于谓词锁定，这是一种隔离机制，通过锁定数据库中的逻辑项而不是物理项来实现模块化。谓词锁定很少用作核心隔离机制，因为它具有很高的理论复杂性和感知开销。但是，我们证明，通过优化常见谓词结构，可以在实践中大大减少这种开销。

  我们提出了DIBS，这是一个事务调度器，它使用我们的谓词锁定优化来保证作为模块化服务的隔离。我们评估了DIBS作为数据处理系统中唯一的隔离机制的性能。在此设置中，在TATP工作负载上，DIBS可扩展到每秒1050万个事务。我们还将探讨如何将DIBS应用于现有数据库系统以提高事务吞吐量。在SQLite中，DIBS将在TATP上每个事务的文件系统写操作减少了90%，从而使吞吐量提高了3倍。最后，DIBS减少了MySQL中YCSB上的行争用，提供了可序列化的隔离，吞吐量提高了1.4倍。



FLAT: Fast, Lightweight and Accurate Method for Cardinality Estimation

+ 关键词：查询优化，基数估计
+ 摘要：查询优化器依赖于精确的基数估计(CardEst)来产生良好的执行计划。CardEst的核心问题是如何精确而紧凑地对属性的丰富联合分布进行建模。尽管经过了几十年的研究，现有的方法要么只使用独立因子分解对模型进行过度简化，导致估计不准确，要么不使用独立假设的无损条件因子分解使模型过于复杂，导致概率计算缓慢。本文提出了一种同时具有概率计算速度快、模型规模轻、估计质量准确的CardEst方法FLAT。FLAT的关键思想是一种新的无监督图形模型，称为FSPN。它同时利用独立因子分解和条件因子分解对不同层次的属性相关性进行自适应建模，并结合它们的优点。FLAT支持在近线性时间内对底层FSPN模型进行高效的在线概率计算，提供有效的精细模型构建并支持增量模型更新。它可以估计单表查询和多表连接查询的基数。大量的实验研究证明了FLAT方法优于现有的CardEst方法:FLAT实现提高1-5个数量级的精度，提高1-3个数量级的概率计算速度，降低1-2个数量级的存储成本。我们还将FLAT集成到Postgres中以执行端到端测试。在众所周知的IMDB基准工作负载上，它将查询执行时间提高了12.9%，非常接近使用真实基数的最佳结果14.2%。



Are We Ready For Learned Cardinality Estimation?

+ 关键词：查询优化，计数估计，ml
+ 摘要：基数估计是查询优化中一个基本但长期未解决的问题。最近，来自不同研究小组的多篇论文一致报道，学习模型有潜力取代现有的基数估计。在本文中，我们提出了一个前瞻性的问题:我们准备好在生产中部署这些学习得到的基数模型了吗？我们的研究主要包含三个部分。首先，我们关注静态环境(即没有数据更新)，并在统一工作负载设置下，在四个真实数据集上比较五种新学习的方法与九种传统方法。结果表明，学习模型确实比传统方法更准确，但往往存在较高的训练和推理成本。其次，我们探究这些学习过的模型是否为动态环境做好了准备(例如，频繁的数据更新)。我们发现它们无法赶上快速的数据更新，并由于不同的原因返回较大的错误。对于不太频繁的更新，它们可以表现得更好，但它们之间没有明显的赢家。第三，我们对学习过的模型进行更深入的研究，并探索它们何时可能出错。我们的结果表明，学习方法的性能可以受到相关性、偏度或域大小的变化的很大影响。更重要的是，他们的行为更难以解释，而且往往难以预测。基于这些发现，我们确定了两个有前途的研究方向(控制学习模型的成本和使学习模型可信)，并提出了一些研究机会。我们希望我们的研究可以指导研究人员和实践者一起工作，最终将学习到的基数估计器推向真实的数据库系统。



PATSQL: Efficient Synthesis of SQL Queries from Example Tables with Quick Inference of Projected Columns

+ 关键词：SQL
+ 摘要：SQL是最受欢迎的数据分析工具之一,它现在被越来越多的用户使用,而没有在数据库中拥有专业知识。一些研究已经提出了以编程为例的方法来帮助这些非专家编写正确的SQL查询。虽然现有的方法支持各种SQL特性,如聚合和嵌套查询,但随着示例表的规模增加,它们在计算成本上有显著的增加。在本文中,我们提出了一种有效的算法,利用关系代数中已知的属性来合成来自输入和输出表的SQL查询。我们的关键见解是，通过在关系代数中应用转换规则，在保留程序语义的同时，可以将程序草图中的投影操作符提升到其他操作符之上。这使得可以在投影运算符中快速推断出适当的列，这是合成中的一个基本组成部分，但在以前的工作中会导致组合爆炸。我们还介绍了一种新的约束形式及其自顶向下的传播机制，以实现高效的草图完成。我们在我们的工具PATSQL中实现了这个算法，并对来自之前基准测试和Kaggle教程的226个查询进行了评估。结果，PATSQL解决了68%的基准，并在一秒钟内找到89%的解。我们的工具可以在https://naist-se.github.io/patsql/上找到。



Fauce: Fast and Accurate Deep Ensembles with Uncertainty for Cardinality Estimation

+ 关键词：ml，基数估计

+ 摘要：基数估计是数据库中一个基本而关键的问题。近年来，人们提出了许多基于深度学习的估计方法来解决这一问题，并取得了良好的效果。但是，这些估计器很难为复杂的查询提供准确的结果，因为它们不能捕获真正的列间和表间相关性。此外，这些估计量都不包含关于其估计的不确定性信息。在本文中，我们提出了一个称为Fauce的连接基数估计器。Fauce学习数据库中所有列和所有表之间的相关性。它还包含了每个估计的不确定性信息。在所有研究过的估计器中，我们的结果是有希望的：1）Fauce是一种轻量级的估计器，它的推理速度比现有的估计器快10倍；2）Fauce对复杂查询具有鲁棒性，与现有的估计器相比，它为复杂查询提供了1.3×-6.7×更小的估计误差；3）据我们所知，Fauce是第一个将不确定性信息整合到深度学习模型中进行基数估计的估计器

  

Flow-Loss: Learning Cardinality Estimates That Mater

+ 关键词：基数估计，查询优化
+ 摘要：近年来，人们对利用机器学习来提高基数估计的准确性非常感兴趣。这项工作的重点是提高平均估计误差，但并不是所有的估计对下游任务(如查询优化)都同等重要。由于学习过的模型不可避免地会出错，所以目标应该是改进对优化器产生最大影响的估计。我们引入了一个新的损失函数，Flow-Loss，用于学习基数估计模型。流损失近似于优化器的成本模型和搜索算法，它使用解析函数显式优化更好的查询计划。Flow-Loss的核心是将查询优化简化为一个特定平面图上的前路径问题，其中不同的路径对应不同的查询计划。为了评估我们的方法，我们引入基数估计基准(CEB)，它包含超过16K 查询的子计划的基本真理基数，这些查询来自21个模板，最多有15个连接。我们表明，在不同的体系结构和数据库中，使用Flow-Loss训练的模型改善了计划成本和查询运行时，尽管其估计精度比使用QError训练的模型差。当测试集查询与训练查询密切匹配时，使用两个损失函数训练的模型表现良好。然而，当对稍微不同的查询(例如，相似但不可见的查询模板)进行评估时，q - error训练模型显著降级，而flow - loss训练模型更适用于这种情况，在具有相同模型架构和训练数据的不可见模板上实现了4 - 8倍更好的99分位数运行时间。



Robustness against Read Committed for Transaction Templates

+ 关键词：事务，隔离级别
+ 摘要：众所周知，许多数据库系统提供的隔离级多版本读提交(RC)是为了提高事务吞吐量而牺牲一致性的。有时，事务工作负载可以在RC下安全执行，以较低的RC成本获得序列化性的完美隔离。为了识别这种情况，我们引入了事务程序的表达模型，以更好地解释事务工作负载的可序列化性。我们开发了可处理的算法来决定在RC下执行的工作负载的任何可能的时间表是否可序列化(称为鲁棒性问题)。我们的方法产生的健壮子集比以前的方法所识别的子集要大。我们提供的实验证据表明，与较强的隔离级别相比，抗RC的工作负载在RC下可以更快地进行评估。我们将讨论通过提升对更新的选择性读操作，使RC工作负载健壮的技术。根据场景的不同，性能的提高可能相当可观。因此，在较低的隔离级别RC下进行健壮性测试和安全执行事务可以提供一种直接的方法，在不改变DBMS内部的情况下提高事务吞吐量。



Scaling Replicated State Machines with Compartmentalization

+ 关键词：状态机，raft，分区
+ 摘要：状态机复制协议，如MultiPaxos和Raft，是许多分布式系统和数据库的关键组件。然而，由于一些瓶颈组件，这些协议提供了相对较低的吞吐量。许多现有的协议孤立地修复不同的瓶颈，但缺乏完整的解决方案。当你解决了一个瓶颈，另一个瓶颈就会出现。在本文中，我们介绍了分区技术，这是第一种消除状态机复制瓶颈的综合技术。划分涉及到将单个瓶颈分离到不同的组件中，并独立地扩展这些组件。划分有两个关键优势。首先，划分会带来强大的性能。在本文中，我们演示了如何划分MultiPaxos，以便在只写工作负载下将吞吐量提高6×，在混合读写工作负载下提高16×。与其他方法不同，我们不需要专门的硬件就可以实现这种性能。第二，划分是一种技术，而不是协议。行业从业者可以增量地将分区应用到他们的协议中，而不必采用一个全新的协议。



Constructing and Analyzing the LSM Compaction Design Space

+ 关键词：LSM树，压缩策略

+ 摘要： LSM tree通过附加写入（append）数据提供了高效的摄入，因此被广泛用作生产NoSQL数据存储的存储层。为了实现有竞争力的读性能，lsm树定期地重新组织数据，通过迭代紧实形成容量指数级增长的树。紧凑从根本上影响lsm引擎的性能，包括写放大、写吞吐量、点和范围查找性能、空间放大和删除性能。因此，选择合适的压缩策略是至关重要的，与此同时，lsm压缩设计空间很大，很大程度上未被探索，在文献中还没有正式定义。因此，大多数基于lsm的引擎使用固定的压缩策略，通常由工程师亲自挑选，由工程师决定如何以及何时压缩数据。

  在这篇论文中，我们提出了 lsm 压缩的设计空间，并评估了最先进的压缩策略与关键性能指标。为了实现这一目标，我们的第一个贡献是引入一组四种设计原语，它们可以正式定义任何压缩策略：(i) 压缩触发器，(ii) 数据布局，(iii) 压缩粒度，以及(iv)数据移动策略。 这些原语可以综合现有的和全新的压缩策略。我们的第二个贡献是实验分析了10种压实策略。我们提出12个观察结果和7个高级要点信息，展示了LSM系统如何操作压缩设计空间。



ByShard: Sharding in a Byzantine Environment

+ 关键词：两阶段提交，存储系统

+ 摘要：区块链的出现推动了弹性系统的发展，这些系统可以处理由于崩溃、bug甚至恶意行为造成的拜占庭式故障。最近，我们还看到了在这些弹性系统中对分片的探索，这可以提供非常大的基于数据的应用程序所需的可伸缩性。不幸的是，当前的分片弹性系统都使用特定于系统的专门方法进行分片，这些方法不能提供传统分片数据管理系统的灵活性。

  为了改善这种情况，我们从根本上研究分片弹性系统的设计。我们通过引入ByShard来实现这一点，ByShard是研究分片弹性系统的统一框架。在这个框架中，我们展示了如何在拜占庭环境中高效地实现两阶段提交和两阶段锁定(在传统分片数据库中提供原子性和隔离的两种关键技术)，并尽量减少使用昂贵的拜占庭弹性原语。基于这些技术，我们提出了18个多碎片事务处理协议。最后，我们对这些协议进行了实际评估，并表明每个协议都支持高事务吞吐量并提供可伸缩性，同时每个协议都在吞吐量、隔离级别、延迟和中止率之间实现了自己的权衡。因此，我们的工作为开发acid兼容的通用和灵活的分片弹性数据管理系统提供了坚实的基础。



SetSketch: Filling the Gap between MinHash and HyperLogLog

+ 关键词：集合算法
+ 摘要：MinHash和HyperLogLog是大数据应用中集合摘要不可或缺的描述算法。HyperLogLog允许在很小的空间内计算不同的元素，而MinHash适合于集合的快速比较，因为它允许估计Jaccard相似度和其他联合量。这项工作提出了一种名为SetSketch的新数据结构，它能够持续填补这两个用例之间的差距。它的交换和幂等插入操作和可合并状态使其适合于分布式环境。快速、健壮且易于实现的基数和关节量估计器，以及使用SetSketch进行相似度搜索的能力，支持多功能应用程序。提出的联合估计器还可以应用于其他数据结构，如MinHash、HyperLogLog或HyperMinHash，在许多情况下，它甚至比相应的最先进的估计器性能更好。



Accelerating Approximate Aggregation Queries with Expensive Predicates

+ 关键词：ML，聚集运算
+ 摘要：研究人员和行业分析师越来越感兴趣的是，通过使用昂贵的深度神经网络(DNNs)计算具有选择性谓词的大型非结构化数据集计算聚合查询。由于这些dnn很昂贵，而且许多应用程序可以容忍近似答案，分析人员对通过近似加速这些查询很感兴趣。不幸的是，加速此类查询的标准近似查询处理技术并不适用，因为它们假定谓词的结果提前可用。此外，最近使用廉价近似(即代理)的工作不支持带有谓词的聚合查询。为了加速使用昂贵谓词的聚合查询，我们开发并分析了一个利用代理(ABae)的查询处理算法。ABae必须考虑关键挑战，即它可能对不满足谓词的记录进行抽样。为了解决这一挑战，我们首先使用代理将记录分组到层中，以便理想地将满足谓词的记录分组到几个层中。对于这些地层，ABae使用先导抽样和插件估计根据最优分配进行抽样。我们证明了在不满足谓词的情况下，在分层抽样的新分析中，ABae以最优速率收敛。我们进一步表明，在6个真实数据集的基线上，ABae的表现优于基线，减少标签成本高达2.3×。



A four-dimensional Analysis of Partitioned Approximate Filters

+ 关键词：过滤器
+ 摘要：在当今数据泛滥的情况下，近似过滤器在避免远程数据/磁盘访问等昂贵操作方面具有特别的吸引力。在许多可用的过滤器变体中，为特定的用例找到最合适的一个及其最佳配置并非易事。我们为最相关的过滤器(Bloom、Cuckoo、Morton和Xor过滤器)提供了开源实现，并在四个关键维度上对它们进行比较:假阳性率、空间消耗、构建和查找吞吐量。我们在现有的最先进的实现基础上进行了优化，即基数分区，这将大型过滤器的构建和查找吞吐量提高了9倍和5倍。我们的深入评估首先分别研究所有可用优化的影响，然后将它们组合起来，为特定用例确定最佳过滤器。虽然寄存器阻塞布鲁姆过滤器提供了最高的吞吐量，新的Xor过滤器最适合优化小过滤器尺寸或低假阳性率。



A Practical Approach to Groupjoin and Nested Aggregates

+ 关键词：查询优化，嵌套查询
+ 摘要：组连接是连接和后续 group by 的组合执行，在分析查询中很常见，在TPC-H和TPC-DS中约有1/8的查询中出现。虽然它们最初是为了提高性能而发明的，但组连接的高效并行执行可能会受到争用的限制，这限制了它们在多核系统中的作用。拥有高效的组连接实现是非常可取的，因为组连接不仅用于融合group by和连接，而且还由查询优化器的反嵌套组件引入，以避免聚合的嵌套循环计算。此外，查询优化器需要能够对聚合结果进行推理，以便正确地调度它。当面对来自嵌套聚合的计算列时，传统的选择性和基数估计很快就达到了极限，这导致成本估计很差，从而导致次优查询计划。在本文中，我们提出了有效估计、计划和执行组连接和嵌套聚合的技术。我们提出了两种新技术:聚合估计来预测聚合的结果分布，以及并行组连接执行来实现可伸缩的组连接执行。得到的系统具有明显更好的估计和无争用的组连接求值，这可以将一些TPC-H查询的速度提高到2倍。



COMPARE: Accelerating Groupwise Comparison in Relational Databases for Data Analytics

+ 关键词：操作运算符，嵌套查询，查询优化
+ 摘要：数据分析通常涉及对多个维度的数据子集进行比较，以发现不寻常的趋势和模式。虽然可以使用SQL表示数据子集之间的差异，但它们编写起来往往很复杂，并且在大型和高维数据集上性能较差。本文提出了一种新的关系数据库逻辑运算符比较，它简洁地捕捉了数据子集之间的枚举和比较，大大简化了大类比较查询的表达。我们对数据库引擎进行了扩展，使用了可利用比较语义的操作时间化技术，从而显著提高了此类查询的性能。我们已经在微软SQL Server中实现了这些扩展，这是一个COM-mercialDBMS引擎.我们对合成数据集和真实世界数据集的广泛评价表明，与现有方法相比，结果有显著的加速，包括由当今数据库系统、用户定义函数(UDF)以及比较数据库之外子集的中间件解决方案组成的物理计划。



Crystal: A Unified Cache Storage System for Analytical Databases

+ 关键词：缓存，云存储
+ 摘要：云分析数据库采用一种分解存储模型，其中弹性计算层以面向块的柱状格式访问远程云存储上持久化的数据。考虑到远程存储的高延迟和低带宽以及快速本地存储的有限大小，在计算节点上缓存数据非常重要，这导致了对用于分析的缓存的新兴趣。如今，每个DBMS构建自己的缓存解决方案，通常基于文件或块级LRU。在本文中，我们提出了一种新的智能缓存存储系统的架构，称为Crystal，它与计算机共存。Crystal的客户端是具有下推谓词的特定于dbms的“数据源”。Crystal在精神上与DBMS类似，它集成了查询处理和优化组件，专注于高效缓存和被称为区域的单表超矩形的服务。结果表明，Crystal使用一个小型的特定于 DBMS 的数据源连接器，可以显著提高未修改的Spark和Greenplum上的查询延迟，同时还可以节省远程存储带来的带宽。



Deep Learning for Blocking in Entity Matching: A Design Space Exploration

+ 关键词：
+ 摘要：实体匹配(EntityMatch，EM)查找引用同一个真实实体的数据实例.大多数EM解决方案都是执行阻塞和匹配，许多工作都将深度学习(DL)应用于匹配，但将DL应用于匹配的工作则少得多。这些阻塞工作也是有限的，因为它们只考虑一种简单的DL形式，其中有些还需要有标记的训练数据。在本文中，我们开发了DeepBlock框架，显着地提高了DL在EM阻塞中应用的技术水平。我们首先定义了用于阻塞的DL解决方案的更大空间，该解决方案包含不同复杂性的解决方案，并包含了大部分以前的工作。接下来，我们在这一领域开发了8种有代表性的解决方案，这些解决方案不需要标记的训练数据，并且利用了DL中的最新进展(例如序列建模、变压器、自我监督)。我们经验地确定哪种解决方案在哪些类型的数据集(结构化的、文本的或脏的)上表现最好。我们表明，在脏数据和文本数据上，最好的解决方案(在上述八种解决方案中)优于最佳存在的DL解决方案和现有的最佳非DL解决方案(包括最先进的工业非DL解决方案)，并在结构化数据上具有可比性。最后，我们表明，最佳DL和非DL解决方案的结合可以更好地实现，这为研究提供了一个新的场所。



Auto-Pipeline: Synthesizing Complex Data Pipelines By-Target Using Reinforcement Learning and Search

+ 关键词：流水线，操作运算符

+ 摘要：最近的工作在帮助用户自动匹配单个数据准备步骤方面取得了重大进展，例如字符串转换和表操作操作符(例如Join、GroupBy、Pivot等)。在本工作中，我们建议通过合成具有字符串转换和表操作操作符的复杂数据管道，实现多个此类步骤的端到端自动化。

  我们提出了一种新颖的逐目标范式，允许用户很容易指定所需的管道，这是一个重大的偏离从传统的举例范例。使用按照目标,用户是否会提供输入表(例如，CSV或json文件)，并向我们指出一个目标表(例如，一个现有的数据库表或BI仪表板)来演示所需管道的输出示意图的样子。虽然这个问题似乎没有明确说明，但我们的独特见解是，隐式表约束是这样的因为可以利用fd和键来显著限制空间让问题变得容易处理。我们开发了一个自动管道该系统学习利用深度强化学习(DRL)和搜索合成管道。实验使用的基准是700个真正的管道是从GitHub和商业供应商那里爬出来的表明Auto-Pipeline可以成功合成70%的复杂管道多达10个步骤。



Explaining Inference Queries with Bayesian Optimization

+ 关键词：查询优化，查询解释

+ 摘要：获取SQL查询结果的解释可以丰富分析经验，揭示数据错误，并提供对数据更深入的洞察。推理查询解释试图解释推理数据上的意外聚合查询结果;这样的查询很难解释，因为可能需要从ML管道中的源数据、训练数据或推理数据中得到解释。

  在本文中，我们将一个目标函数建模为一个黑箱函数，并提出了BOExplain，一个使用贝叶斯优化(BO)解释推理查询的新框架。解释是定义应该删除的输入元组的谓词，这样就会显著影响相关的查询结果。BO 一种寻找黑盒函数全局最优解的技术用于查找最佳谓词。我们开发了两种新技术(个体贡献编码和温暖启动)来处理分类变量。我们进行的实验表明，与最先进的查询解释引擎所找到的谓词相比，BOExplain找到的谓词具有更高的解释程度。我们还展示了BOExplain在从各种真实数据集的源数据和训练数据中为推理查询派生解释方面是有效的。BOExplain是开源的Python包，在https://github.com/sfu-db/BOExplain提供下载。



Decomposed Bounded Floats for Fast Compression and !eries

+ 关键词：压缩，数据密集型应用，SIMD

+ 摘要：现代的数据密集型应用程序经常生成大量精度不高、取值范围有限的数据。尽管这样的数据很流行，但缺乏一种有效的解决方案来摄取、存储和分析有界的、低精度的数字数据。

  为了弥补这一差距，我们提出了Buff，一种新的压缩技术，它使用分解的柱状存储和编码方法，提供有效压缩、快速摄取和高速原位自适应查询操作符，并支持SIMD。



Beyond Equi-joins: Ranking, Enumeration and Factorization

+ 关键词：连接查询优化
+ 摘要：我们研究了一般的 $\theta$-连接，以及带有连接和分离不等式的连接谓词，重点关注排序枚举，其中答案按照给定排序函数指定的顺序递增返回。我们的方法实现了强大的时间和空间复杂性属性：$𝑛$ 表示数据库中元组的数量，我们保证对于具有不等式条件的无环全连接查询，对于 $𝑘$ 的每个值，$𝑘$ 的排名靠前的答案将在 $O(npolylog𝑛+𝑘log𝑘)$ 时间内返回。这是有有多对数因子 $O (𝑛 + 𝑘 log 𝑘)$,等效连接最著名的复杂性。即使是 $O(𝑛+𝑘)$，查看输入并按任意顺序返回𝑘答案所花费的时间。我们的保证扩展到使用选择和许多类型的投影（即所谓的“自由连接”查询和使用包语义的查询）连接查询。值得注意的是，即使连接ℓ个relations，它们也保持连接结果的数量是$𝑛^ℓ$不变。关键成分是查询输出的新颖大小$O(𝑛polylog𝑛)$的分解表示，它是为给定的查询和数据库动态构造的。除了提供了超越等价连接的第一个非微不足道的理论保证之外，我们在一项实验研究中表明，我们的排序枚举方法在实践中也是内存高效和快速的，比最先进的数据库系统的运行时间快了几个数量级。



MultiCategory: Multi-model Query Processing Meets Category Theory and Functional Programming

+ 关键词：查询系统，数据结构
+ 摘要：数据的多样性是大数据时代的重要问题之一，数据自然以不同的格式和模式来组织，包括结构化数据、半结构化数据和非结构化数据。以往的研究提出了一种利用范畴理论抽象多模型数据的方法，包括模式分类和实例分类。本文介绍了一个基于范畴理论和函数式编程的多模型查询处理系统。这个演示以四个主要场景为中心来展示一个有形的系统。首先，我们展示了如何通过加载不同的数据模型(包括关系、XML、键值和图形数据)来构建模式类别和实例。其次，我们展示了使用函数编程语言Haskell进行查询处理的几个例子。第三，对同一输入查询的不同数据模型的柔性输出进行了演示。第四，为了更好地理解查询背后的理论结构，我们提供了各种图形钩子来探索查询，并将查询可视化为与模式类别有关的图形，以及Haskell查询处理过程。



Low-Latency Compilation of SQL Qeries to Machine Code

+ 关键词：查询优化，编译器优化
+ 摘要：查询编译已被证明是最有效的查询处理技术之一。尽管处理速度快，但该技术的附加编译次数限制了它的应用，因为只有当处理时间的改进明显超过额外的编译时间时，这种方法才是最有益的。最近，查询编译器的可行性被证明了非常低的组成时间.这可能证明查询编译只是一种普遍的方法。在本文中和Corre-Responding现场演示中，我们展示了ReSQL数据库系统的功能，它使用中间表示形式Flounder IR来实现非常低的编译时间。与现有的基于LLVM的分析查询技术相比，ReSQL将从SQL到机器代码的编译时间减少了101.1x。



PostCENN: PostgreSQL with Machine Learning Models for Cardinality Estimation

+ 关键词：ML，基数估计
+ 摘要：在这个演示中，我们提出了PostCENN，一个增强的PostgreSQL数据库系统，它具有机器学习(ML)模型的端到端集成，用于基数估计。一般说来，基数模型在数据库界是一个历史悠久的话题，虽然直方图等传统模型被广泛使用，但研究主要集中在利用MLModel开发新的方法上，但传统模型和ML模型各有其优点和劣势，利用PostCENN，将ML模型作为提高数据库模式某些部分基数估计精度的一种新手段，将两者结合起来，将ML模型作为一种新的手段来提高数据库模式某些部分的基数估计的准确性。为了实现这一目标，我们将ML模型作为PostgreSQL中的第一类公民与定义明确的结束生命周期结合起来。这个生命周期包括为数据库模式的不同子部分创建ML模型，触发培训，以透明的方式在查询优化器中使用ML模型，以及删除ML模型。



DBMind: A Self-Driving Platform in openGauss

+ 关键词：自主驱动，ML
+ 摘要：我们演示了一个自主驱动的DBMind，它在数据库中提供了三种自动驾驶功能，包括自监控、自诊断和自优化。首先，自我监控明智地收集数据库指标并检测异常(例如，缓慢的查询和IO争用)，这可以分析数据库状态，而只轻微影响系统性能(&lt;5%)。然后，自诊断利用LSTM模型分析异常的根本原因，并从预定义的故障层次结构中自动检测根本原因。接下来，自优化使用基于学习的技术自动优化数据库性能，包括基于旋钮调优的深度强化学习、基于强化学习的索引选择和基于编码器-解码器的视图选择。我们在开源数据库opengauss中实现了DBMind，并演示了真实的场景。



AnyOLAP: Analytical Processing of Arbitrary Data-Intensive Applications without ETL

+ 关键词：OLAP，数据分析

+ 摘要：现代数据密集型应用程序处理和产生的数据量正在不断增加。当然，随着数量的增加，分析和解释这些数据的兴趣也增加了。因此，越来越多的dbms和处理框架专门用于高效执行长时间运行的只读分析查询。不幸的是，要启用分析，首先必须通过漫长的ETL过程将数据从源应用程序移动到分析工具，这增加了分析管道的运行时和复杂性。

  在这项工作中，我们主张简单地跳过ETL。通过AnyOLAP，我们可以直接在源应用程序内部以及在源应用程序运行时对数据进行在线分析。在提议的演示中，观众将有机会在一组数据密集型应用程序上对AnyOLAP进行测试，这些应用程序将在启动和运行时进行分析。由于AnyOLAP的整个分析管道将以实时和交互式可视化的形式向观众展示，用户将能够亲身体验真正在线分析的好处。



An Intermediate Representation for Hybrid Database and Machine Learning Workloads

+ 关键词：系统框架，编译，OLAP查询
+ 摘要：IFAQ是一种用于混合数据库和机器学习工作负载的中间表示和编译框架，可使用带有函数聚合查询的迭代程序来表示。我们演示了几种OLAP查询、线性代数表达式以及在关系数据库上的特征提取查询定义的训练数据集上的学习因子分解机的IFAQ。



A Demonstration of NoDA: Unified Access to NoSQL Stores

+ 关键词：NoSQL
+ 摘要：在这篇演示论文中，我们展示了一个名为NoDA的系统原型，它通过向大数据开发人员公开单一接口，统一了对NoSQL存储的访问。这隐藏了NoSQL存储的异构性，包括不同的查询语言、非标准化访问和不同的数据模型。NoDA由位于NoSQL存储层之上的一层组成，该层定义了一组基本数据访问操作符(过滤器、项目、聚合等)，针对不同的NoSQL引擎实现。通用数据访问操作符的提供支持使用SQL作为查询语言的声明性接口。此外，NoDA还被扩展为提供更复杂的操作符，例如地理空间操作符，NoSQL存储只部分支持这些操作符。我们通过展示完全相同的查询可以由不同的NoSQL存储处理，而不需要任何修改或转换来演示NoDA。



AutoExecutor: Predictive Parallelism for Spark SQL Queries

+ 关键词：Spark，查询预测
+ 摘要：正确分配用于查询执行的资源对于低成本的性能非常重要，但是在查询执行之前估计资源分配对性能的影响是很困难的。我们演示了AutoExecutor，这是一个预测系统，它使用机器学习模型来预测查询运行时间，作为分配的执行器数量的函数，它限制了在Azure Synapse上运行的Spark SQL查询的最大允许并行度。



Not Black-Box Anymore! Enabling Analytics-Aware Optimizations in Teradata Vantage

+ 关键词：sql执行引擎，查询优化
+ 摘要：eradata Vantage是一个平台，可将广泛的分析功能和功能与Teradata的SQL引擎集成在一起。优化这些分析函数执行的主要挑战之一是，它们中的许多不仅是黑盒，而且具有多态性质，也就是说，它们的行为和属性可能会根据调用上下文而变化。在本文中，我们首先演示了优化多态函数的内在复杂性，然后介绍了Vantage的协同优化器，这是一个跨平台优化器，设计用于优化从SQL引擎内部调用的分析函数。协同优化器是业界首次致力于在多态分析函数上实现分析感知优化。我们提出了一种新的基于标记语言的方法，通过一组定义良好的指令来表示函数的多态属性。协同优化器在查询时使用这些指令推断相应的属性，然后决定适用的优化。从几种可能的优化中，我们展示了两种核心优化，即“投影推送”和“谓词推送”，其目的是优化与分析函数之间的数据移动。使用Teradata-MLE分析系统的实验证明了所提出的标记语言的表达能力和灵活性。此外，基准测试和真实客户查询显示了Collaborative Optimizer为Vantage系统带来的显著性能增益。



openGauss: An Autonomous Database System

+ 关键词：ML，框架系统
+ 摘要：尽管近年来学术界已经对基于学习的数据库优化技术进行了研究，但它们还没有在商业数据库系统中得到广泛应用。在这项工作中，我们构建了一个自主数据库框架，并将我们提出的基于学习的数据库技术集成到一个开源数据库系统openguss中。我们提出了有效的基于学习的模型来构建习得的优化器(包括习得的查询重写、习得的开销/基数估计、习得的连接顺序选择和物理操作符选择)和习得的数据库顾问(包括自监控、自诊断、自配置和自优化)。我们设计了一个有效的验证模型来验证学习模型的有效性。我们建立了有效的训练数据管理和模型管理平台，轻松部署学习到的模型。我们已经在真实的数据集上评估了我们的技术，实验结果验证了我们的技术的有效性。我们还提供了部署基于学习的技术的经验。



Big Metadata: When Metadata is Big Data

+ 关键词：元数据管理
+ 摘要：像谷歌BigQuery这样的云数据仓库的迅速出现重新定义了数据分析的前景。随着数据量的增长，这样的系统在不久的将来需要扩展到数百个EiB数据。这种增长伴随着存储对象数量的增加以及这种系统必须管理的元数据数量的增加。传统上，大数据系统试图减少元数据的数量，以扩大系统的规模，这往往会影响查询性能。在谷歌BigQuery中，我们构建了一个元数据管理系统，该系统演示了不需要这样的权衡就可以实现大规模的规模。我们认识到细粒度元数据为查询处理提供的好处，并构建了一个元数据系统来有效地管理它。我们使用与管理数据相同的分布式查询处理和数据管理技术来处理Big元数据。如今，BigQuery使用这些技术来支持对数十亿个对象及其元数据的查询。